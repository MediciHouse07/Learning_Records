https://www.coursera.org/learn/generative-ai-for-everyone/lecture/YXvSW/trying-generative-ai-code-yourself-optional

# How Generative AI works

0000<->0500

2024/11/27

- how text generation works
- supervised learning, labeling things
- reinforcement learning
- a lot of memory

0000<->1000

2024/11/24

- scope project/
- build improve system/
- inital prototype 
- internal evaluation/
- deploy and monitor back to internal evaluation/
- under performing on some cusines
- experimental process
- repeatedly find and fix mistakes
- token, word or a part of a word


https://learn.deeplearning.ai/courses/chatgpt-building-system/lesson/1/introduction

# chain of thought reasoning

2024/11/23

0000<->0700

- inner monologue

# moderation

2024/11/23

- moderate
- responsibly
- moderation API
- responsible use
- moderate api, moderation api
- change policy to be more strict through API
- unintended usage
- prompt injection, let system_message deviate from its original setup
- max token would control the length of output

0800<->1800

2024/11/22

- trick to fix not translating correctly letters with -
- system, user, and assistant message
- secure ways of storing or publish code
- prompting is revolutionizing AI application development, is it still?

2024/11/21

- LLM use supervise learning to train how to populate the next few words
- repeatedly predict the next word
- hundred and billions
- two types of LLM
- base LLM
- instruction tuned LLM
- months to build LLM
- RLHF, reinforcement learning from human feedback
- predict the next token
- not common in language, then it would be also wrongly tokenized)
