35 lectures in TTL
### Questions: <br>
PDF PMS CDF, always forgot the difference between them
### Lecture 1 <br>
#### REX 1 2022/02/20
#### REX 2 2022/08/13

2022/08/13

3000<->End

- 3600 mins, if k>n = n choose k 0, n choose k (n k) = n!/n- k!k!
- proof of n choose k
- think in terms of multiplication rule
- 4300 mins sampling table

2022/08/12

1500<->3000

- experiemnt can be anything, you do something, something happens
- sample space, is all possible outcomes of an experiment
- event is a subset of the sample space
- 2148 mins, naive defn of prob, P(A)=#favorable outcomes, favored by A/# possible outcomes
- assumes all outcome are equally likely, finite sample space
- for example, if there is alien, mistakely using naive definition if 1/2
- 3100 mins, multiplication rule

2022/08/10

0000<->1500

- 0646 mins, naive definition of probability
- last time? it seems there is another course before this course
- Mosteller, founder of stats institution in harward
- Govt IQSS, politics and stats probability come together
- Gambling game, Fermat, Pascal, 1650, letters
- math is logic of certainty, statistics is logic of uncertanty
- 1500 mins, naive definition

2022/02/20: finished
### Lecture 2 <br>

#### REX 2 2022/08/22
#### REX 1 2022/02/23

2022/08/22

3000<->End

- proof by interpretation
- vandermonde 3618 mins
- 4300 mins, non naive definition of probability
- S is a sample space, P(S)=1, S is the whole universe
- are disjoint

2022/08/21

1500<->3000

- different way to represent the same situation, such as put dots in different boxes, or using a bar between different groups of dots

> The beauty of math is, you can simulate a result of a thing, without really using material
> Hi history me, sitting on a coach, wearing a heavy clothe to keep warm, in the mid night, watching this video

2022/08/20

0000<->1500

- self annotating
- 10 people, split into team of 6, team of 4
- and 2 teams of 5 are different
- n-1 choose 0 is 1, only way one to choose that is not to choose, n-1 choose n is 0, because you can't choose n from n-1

2022/02/23: finished
### Lecture 3 <br>

2022/09/02

3000<->End

- wishful thinking
- matching problem & taylor series, TBRT

2022/09/01

1500<->3000

- drink milk in the morning
- disjoint events
- if A<B then P(A)<P(B)
- proof of P A Union B

2022/08/30

0000<->1500

- birthday problem
- pigeonhole principle
- store information in computer science
- 23 people will give 50%
- 50 people will give 97%

2022/02/24: 1219/4854 birthday problem<br>
2022/03/24: finished, the last problem is hard, I might need to listen the question again, and has something to do with taylor series, 1-1/e
### Lecture 4 <br>

2022/09/25

4500<->End

- n factorial THMs

2022/09/24

3000<->4500

- conditional probability, evidence added
- conditioning is the soul of statistics
- a notebook, that can be used to seach all my words
- dependent and independent
- intuition brain and logical brain
- if conditioning on B, then B is the only universe, the B complementary is excluded
- renormailize
- intuition 1 and intuition 2
- pebble world and frequentist world
- 4421 mins, example of frequentist world

2022/09/23

1500<->3000

- independence, conditional probability
- Newton pepys problem
- assumption makes naive definition applicable
- SIGMA binomial probability

2022/09/22

book page 25<->26

- Reviewed the part in the 20220921 study in the book de Montmort matching problem

2022/09/21

0000<->1500

- matching problem
- jth card in deck is labeled j
- maybe need to review the book to get a concrete idea of it
- e to the x evaluate at x equal minus 1
- 2 computing forces end in 1/e
- next step is to define independence

2022/09/20

0000<->1000

- by symmetryc, subscript can be anything
- 0400 mins, probability and conditional probability
- symmetry is the key to this section
- this is also an application of inclusion and exclusion
- the card you name is the card that appears, but it can think in another way, the deck is randomly arranged
- how to interprete P(U A)? why the formula strart with 1 - 1/2! ...
- OK, it might be the probability of matching 1 2 3 4, and the opposite is probability of no match
- only intersection of A complement can be think of as exactly no match, otherwise it has at least one match

2022/09/19:

0000<->1000

- by inclusion and exclusion
- matching problem is in the end of the last lecture
- add P and subtract P for intersection
- the first k is labbeled
- didn't follow, something were forgot
- complement of a union is intersection of a complement
- taylor series e^x
- TBRT

2022/03/26: finished, the begining of this lecture has a continue relation with the end of Lecture 3 <br>

### Lecture 5 <br>
#### REX 1 2022/03/31
#### REX 2 2022/08/03

2022/10/09

3500<->End

- prior before we have the evidence, posterior after we have the evidence
- PA prior, PA|A posterior
- chess opponnent of unknown strength
- condition on how strong the person is, all the game are independent; not condition on how strong the person is, ealier game gives you evidence so not independent
- 4708 mins another direction of indept and dept
- fire alarm example
- indept F and C, but it would be dependent given A

2022/10/08

3000<->4500

- with the new evidence, update the probability
- bayes rule has coherence property
- probability and law, example 3500 mins
- include independence thinking and bayesian thinking
- prosecutor fallacy
- statistical science in a court room, statistics for a lawer 2 books recommendation
- prior, postererior
- PA is not one, PA|A is one
- confusing independence with conditional independence 4107 mins
- CI given C doesn't imply independence

2022/10/07

1500<->3000

- specify the type of the ace, the probability doubled
- counter intuition
- 2100 mins another example about conditional probability
- 2252 mins, intepretation of the assumption
- what patient cares about
- an example of using LOTP makes problem easier
- 1%, 95%
- second test is not independent
- competition between how rare a disease and how are a wrong test
- frequentist

2022/10/06

0000<->1500

- simulation game
- measure uncertainty
- pie and incorrect evaluation
- break up problem into simpler pieces
- partition = disjoint and complete the whole picture
- 0722 mins, law of total prob
- 0944 mins, example of LOTP
- ace of spades
- stops at the second question of the example

2022/08/03:

3100<->End

- intersection of clue, or one after another one will end up with the same probability
- innocent given evident, evident given innocent
- 3800 mins statistical science for the court book
- prior, posterior
- indep and conditional indep
- conditional indep doesn't imply indep
- 4900 mins indep doesn't imply conditional indep

2022/08/02:

1600<->3100

-  demographic
- disease and test
- 2442 mins bayes rule and LOTP
- rare of disease and rare of test is wrong, both matters

2022/08/01:

0000<->1600

- decompose smaller pieces
- 0700 mins LOTP
- 2 poke card example
 
2022/03/30: 1907/5001 law of total probability, conditionging<br>
2022/03/31: finished, conditioning independent doesn't imply unconditioning independent and vice versa
### Lecture 6 <br>

#### REX 2 2022/10/30

2022/10/30

3000<->End

- conditional and unconditional gets different results
- simpson's paradox and policy implication
- confounder
- relates xx to

2022/10/29

1500<->3000

- 1500 mins, one easy way to inteprete the formula
- LOTP
- what to condition on
- LOTP application 1700 mins, on Montyhall problem
- by symmetry
- asymmetry case
- simpler and extreme case
- simpson's paradox 2800 mins
- aggregate data together the outcome might flip
- next is the reason

2022/10/28

0000<->1500

- Monty hall problem, three door problem
- Monty always open a goat door
- lazy monty hall

### Lecture 7

2022/11/12

4500<->End

- event, the set that makes X(s)=1
- binomial distribution
- probability mass function
- X+Y ~ bin n+m,p

2022/11/11

3000<->4500

- no probability left for oscilation
- prob is 0 of gaming going on forever
- the definition of random variable
- vague
- 3808 mins, the difference between variables and R.V.
- R.V. is a function from sample space to R
- reconcile
- numerical summary
- 4322 mins, Defn Bernonlli
- P(X=1), X(s)=1
- Binomial n p

2022/11/09

1500<->3000

- 1500 mins difference equation
- discrete analog of differential equation
- be professional, and other's attack
- unfair solution will converge to fair solution when the game converges to fair

2022/11/08

0000<->1500

- p is P(A wins a certain round)
- condition on the first step
- a formula is written down


2022/03/29: ðŸ’« 2618/5145 , it has someting to do with Lecture 5, law of total probability <br>
2022/03/30: 2618 around, just to review basing on the law of total probility, see what is the new understanding <br>
2022/03/31: finished, excellent course, random variable, is a function which maps result happened in sample space S to X(s), then you got a distribution, the distribution indicates the variness/randomness of the variable, PMF is just like, P(X=3) if you through a coin, probability of number of heads equals to 3 <br>


2022/05/14:

0000<->3000 mins
0100 mins, statistics 110 5 word, conditioning the soul of statistics, r.v. and its distribution;
0913 mins, random walk, absorbing states, TBR eigen value and eiven vector;
1057 mins, recursive property;
1206 mins, condition on something, wish something;
1500 mins, difference equation;
1900 mins, solve differential equation, one method is to guess;
2621 mins, lowbetaw TBR, 0/0;

2022/05/19:
finished,
3000<->End
3306 mins, gambler's ruin, says probability of game going forever, because the result of P(A)+P(B)=1;
3400 mins, r.v.;
3900 mins, r.v. is a function, that map an abstract outcome to a real number;
4500 mins, X=1 is event, the event is {s:X(s)=1};
4754 mins, distribution is blue print of each probability that a r.v. will be a specific number;
### Lecture 8

2022/12/01

3530<->End

- write down the formula is not end of proof, you also need to check if it fits the sanity check
- if the sample size is big also if the number that choose is small, with replacement and without replacement concides to with replacement

2022/11/30

3000<->4500

- independent and the same probability of success
- a function from sample space to a number
- has k tagged elk
- if choose k from w, if k is bigger than w, then the C is 0
- sampling with replacement is binomial
- sampling without replacement is hypergeometric

2022/11/28

3000<->4500

- if it is independent, it is binomial, if it is not, it is not
- number of aces in the deck
- the elk problem
- 4350 mins, hypergeometric
- TBRT

2022/11/26

1500<->3000

- hybird variable
- sanity check
- binomial therom
- independent we know x without knowing anything about j
- 2850 mins, by independent
- 3000 mins vandermonde

2022/11/25

0000<->1500

- Bin(n,p)
- story
- X=X1+X2+...+Xn, Xj=1 or 0 depends on if the trial is success or failure
- independent, identical, distribution
- R.V. is a function and distribution, how the probability distributed
- x=7 is an event, X<=7 is an event
- cumulative distribution function
- discrete, something you can list

2022/03/31: 2111/5023 around 14 minutes CDF and PMF, both are a way of describing distribution, CDF P(X<=x), PMF P(X=aj) only applies for discrete problem <br>
2022/03/31: finished, around 2857 minutes by independence, knowing A gives no information about B, vandermonte sigma j=0 to k(m choose k-j times n choose k)=m plus n choose k, 10/100000 will make the difference between with replacement and without replacement sort of the same
### Lecture 9 <br>

2022/12/16

XX<->End

- reframe and construct a formula from a known and existing formula
- X~(Geom(p)), E(X)
- iteration way to calculate Ex

2022/12/15

3000<->4500

- binomial formula, if you rephrase it it is (p+q)^n=1
- linearity
- even if X Y are dependent
- np by linearity, since X=X1+X2+..+Xn
- 3800 mins, by indicator, by linearity, by symmetry, by fundamental bridge
- geometric distribution
- Geom(p)
- number of failures before the first success
- geometric series gives the geometric probability name
- binomial therom gives the binomial distribution name

2022/12/14

1500<->3000

- average one number summary
- sum over finite list
- indicator R.V.
- E(X)=P(A)
- A occur
- the rest part sum to 1, binomial therom

2022/12/13

0000<->1500

- P(X<=x) as a function of real x, is CDF
- P(X=1) 2 3 4 is PMF, is the jump
- right continuous
- properties of CDF
- increasing, x tend to infinity
- joint CDF
- knowing of probability of one case, doesn't tell you the probability of another case, that is independent

2022/03/14: ðŸ’« finished, in order to understand so called taylor Expectation in link [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/03/31: finished, 2635 minutes Expectation and P has a bridge; 3248 minutes linearity, EX+Y=EX+EY no matter it is dependent or independent; bridge X={1 if A, 0 otherwise, this is indicator R.V. ; 4158 check PMF, geo distribution; 3827 by symatry and bridge

2022/05/24:

0000<->1500 stop at average and mean

0000 mins;

- CDF is a function of real x, not X
- x-> minus infinity, F(x)->0, x -> infinity, F(x)->1
- independence slogan is multiply
- joint probability
- independent of r.v.
- 

1500 mins;

2022/05/25:

1500<->4000

1500 mins

- 2 ways of calculting mean
- fundamental bridge
- unweighted = same weight, weighted = different weight
- E(X) = sigmax x P(X=x) sum over x with P(X=x)>0
- E(X) = 1P(X=1) + 0P(X=0)=P
- indicator r.v.
- k depends on k, n does not depend on k
- QSN why he can re-write the formula, change k=0 to k=1 and why the following equation like that
- because he take one P out

3000 mins

- linearity, true if X and Y are dependent
- bin = np, since X=X1+X2+...+Xn, Xi are ber
- hypergeometric, linearity + indicator + symmetric + fundamental bridge
- 5 card hand, X=#ace, E(X) is the question
- a dependent case of linearity

4500 mins

2022/05/26:

finished,
4000<->End

4000 mins

- geometric distribution is different with hyper geometric
- TBR hyper geometric, just like binomial but not replacement?
- # failures before the first success , each trial is a bern
- Geom(p)
- check if the PMF valid
- X ~ Geom(p), E(X)=q/p
- 

End mins

### Lecture 10 <br>

2023/01/05

3440<->End

- intermediate point, end point
- infinity=E(2^X) not equal 2^EX=4
- EX=2???

2023/01/03

3000<->4500

- Putnam exam
- Random permutation, all the permutation are equally likely
- local maxima
- on average how many local maximum
- indicator R.V.
- 7 is bigger than 4 is not independent with 7 is bigger than 5
- St Peterburg paradox
- Y=2^X find E(Y)

2023/01/02

1500<->3000

- r.p negative binomial
- number of failure before the rth success
- indep bern trial
- Xj~Geom(p), Xj are independent
- X~FS(p)
- Y=X-1 (Y and X means number)
- Putnam

2023/01/01

0000<->1500

- 2 ways of calculate average, naive way, weighted way
- 0500 mins, wishful thinking
- add 2 function
- X(s), Y(s)
- undemocratic

2022/12/31

0000<->1500

- expectation doesn't exist
- TBRT
- X=0 X=1 X=2 X(s)P({s})
- negative binomial

2022/03/14: ðŸ’« 0610/5010 in order to understand so called taylor Expectation in link [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/03/31: 2230/5010, 1026 minutes, add 2 functions = compute 2 function and add the result; ends at negative nomial distribution <br>
2022/04/01: finished, round 29 minutes negative binomial distribution, first success distribution; 39 minutes, indication + linearity + symetry, and pubble world
### Lecture 11 <br>

2700<->End

2023/02/13

- how many rain drop hit this piece of paper in a minute
- small probability and big number of trials
- he said rain might not be exactly independent
- 2 rain might fall in one small cell
- 1000 factorial is hard for computer to manage
- 3 people birthday problem is difficult to handle in the old way
- 3900 understand the probability and expectation
- n choose 3 is big number number of trial is large, each trail is a small group of people, the indicator reflect the same birthday is unlikely
- not independent, 123 and 124
- the last discrete distribution

2500<->4000

2023/02/12

- see how the converge
- the definition of e^x
- show binomial converge to poisson
- even though n is 23, n choose 3 is large
- triplet
- in increasing order
- exact expectation

1000<->2500

2023/02/11

- discrete model most often used in practice
- large trial, small chance of success
- there are a lot of them
- pois, some cases there is upper bound
- #of Aj's occur is approx pois, lambda is sum of pj
- P(lambda), lambda is sum of pj
- limit kick in
- 2400 starting setup
- E(binomial) is np, set lambda =np, constant
- try to explore the connection between them

2023/02/09

1000<->2200

- independent, weakly dependent
- binomial np converge to pois
- small prob of success, large number of trial
- linearity doesn't care dependency
- need to check pois book

1500<->3000

2023/02/08

- pois paradiagm
- pois approximation
- weekly independence
- TBRT
- n choose k

0000<->1500

2023/02/07

- confuse with r.v. and its distribution
- word is not the thing, the map is not territory
- r.v. is a house, distribution is blueprint of the house
- valid
- #emails in an hour
- empirical, but this is an approximation
- #choclate chip in choclate cookie

2022/04/01: finished, around 21 minutes, by linearity, binomial converge to poisson, e^x = 1 + e/1 + e^2/2 + ... e^n/n! ; need to check calculus, rate of change, law of lopital <br>
2022/04/26: finished, 0500 mins, random variable - house, distribution - blue print;
0750 mins, poisson, P(X=k), k=0,1,2 lambda>0;
1300 mins, poisson like binomial, number of success;
2200 mins, poisson can have different Pj, events can be dependent;
2900 mins, e^x = (1+x/n)^n, compound annual ?interest?;
3700 mins, Iijk indicator R.V.

### Lecture 12 <br>

2023/02/27

-15mins<->End

- VAR X
- need PDF of Y
- traditional way is to find out distribution of gx first, then calculate the expectation
- by LOTUS, you can use the distribution of x
- strictly increasing makes inverse of it still hold inequality, and continuous

2023/02/26

- uniform distribution
- completely random, the probability for all the points are the same
- uniform probabity is propotional to length
- F(x) increases linearly
- Law of the unconscious statistician, LOTUS
- variance of unif(0,1)
- from uniform you can simulate any distribution no matter how complicated it is
- universality of uniform

2023/02/25:

1500<->3000

- FTC version 2
- foundamental therom of calculus
- F is assumed to be always differentiable
- one number of summary
- absolute value, V shape, not differentiable
- mile, square of mile
- EX is a constant
- Variance inequality
- uniform distribution

2023/02/24

0000<->1500

- PMF PDF
- probability per something, PDF probability density function
- defn, r.v X has PDF fx if P(a<=X<=b), integrate this PDF you get probability
- to be valid, fx>=0 integrate to be 1
- in a very small interval, the integral can be function times a constant
- continuous in this case means x can take continuous variable
- F is CDF, P is PDF PMF

2022/04/02: finished, around 1616 minutes FTC from calculus; 3803 minutes, take a function of R.V. is a R.V. ; law of the unconsicious stastician, LOTUS E(g(x))=accumulate from -infinite to +infinite g(x)fX(x)dx; uniform can be everything, just like a indicator I, 4907 minutes, P(F-1(u)<=x)=P(u<=F(x)) because CDF is continously increasing <br>
2022/04/27: finished, 0300 mins, fX(x) specific for PDF, P(X=x) is PMF, f(x) is not probability but it is PDF, intergral is probability;
1500 mins, FTC;
1839 mins, assume derivative exist, for CDF;
2039 mins, expectation is one number summary, variance is spread, absolute value is not differeantiable;
3216 mins, uniform probility propotion to length, completely random;
3924 mins, LOTUS first show;
4423 mins, unif(0,1) can generate all distribution;
4800 mins, proof of uniform is universal, condition of inverse, 1. strictly increase, 2. continuous, to prove this THM you need to know what is CDF, P(X<=x)=F(X)
### Lecture 13 <br>

2023/03/11

3600<->End

- infinite integral and finite integral
- odd function, by symmetry
- integrate by part, one piece easy to integrate, another piece easy to differentiate
- infinite integral and finite integral and integral by part
- var of normal distribution
- standard normal = 1-standard normal, by symmetry

1500<->4000

2023/03/10

- independence, joint PMFs, joint CDFs
- fully independence
- pair wise independence is not enough to claim independence
- give him credit
- adding a large number of r.v. the result is going to be in the same shape, bell shape curve
- dding a lot of iid looks normal
- c is whatever constant we need to make function to be one
- write the same thing twice
- understand how to rearrange the order of elements in a formula
- jacobian, read math review
- transform in more than one dimension, times it by jacobian

2023/03/09

0000<->1500

- start with a CDF, not to start with a random variable
- rewrite the formula in terms of u
- the value of inverse function and simulation
- linear is uniform, u square is not uniform

2023/03/08

0000<->1500

- garbage in garbage out in bayes rule
- any function has the property of the CDF then it is a CDF
- self referential
- TBRT
- take one example exponential distribution
- 1100 mins simulation example, and universality example
- solve the inverse equation in terms of another variable
- symmetry of uniform
- linear of uniform is uniform, non linear is not uniform

2022/04/02: finished, 0039 minutes court UK, can't use bayes to defends; 0701 take a function of R.V. is still R.V.; 1200 minutes, simulation; 1455 minutes, linear uniform -> uniform, non-linear uniform -> non-uniform; 1640 independent R.V. and independent event; 3508 double intergral; 3743 handout, jacobian, math about integration <br>
2022/05/02: finished, 0300 mins, universality of universe, CDF, right continus, <- = 0, -> = 1, strictly increase;
1-1/e^x, exponential distribution;
1339 mins, 1-unif ~ unif, symmetry of unnif, a+bu is unif on some interval;
1800 mins, definition of independent, TBR the first time independent is mentioned;
participating;
3500 mins, merge 2 intergral to a double intergral, because when you do it one by one, you will treat one as constant;
3700 mins, Jacobian, TBR, in math handout;
2100 mins, case of pairwise independent <> independent;
3100 mins, taylor series and e^x, antiderivative, porlar coordinate;
3900 mins, intergral e^-u du = 1;
4800 mins, integral by part
### Lecture 14 <br>

3400<->End

2023/03/22

- if 2 variables are independent, var x+y is varx + y
- prove LOTUS for discrete sample space
- S:X(s)=x
- seems he didn't say why the probability of gx is the same as x

2023/03/21

3000<->4500

- derive variance of poisson
- get cross terms
- I1 times I2 is indicator of success on both trials
- second moment of binomial
- hyper geometric, geommetric
- prove LOTUS for discrete sample space

2023/03/20

1500<->3000

- the relationship between CDF P and phi
- understand what does capital phi mean
- even though you have negative number, LOTUS says the flavor still work
- replennish
- from expectation of poisson to variance of poisson

2023/03/19

0000<->1500

- EZ first moment, EZ^2 second moment
- EZ^3 thrid moment
- -Z is standard normal as well
- rescaling things
- variance is not in the linear world
- x is not iid with itself, x is strictly dependent with itself
- standarization

2022/04/02: finished, 131 minutes 1st moment, 2nd moment; ðŸŒŸ idea mind flow, key ord and their reason; 1030 minutes, var; 1856 minutes, sum of iid, normal X1-X2~(u1-u2, sigma1^2+sigma2^2); 4458 minutes, prove LOTUS

2022/05/09:
0000 mins,
Normal, E(Z)=0, VAR(Z)=E(Z^2)=1, E(Z^3)=0
0417 mins, -Z is a normal by symmetry;
0522 mins, mean location, SD scale;
0706 mins, VAR(miu + sigma z);
0922 mins, P(X=1)=1 VAR(X)=0;
1037 mins, VAR(X+Y)=VAR(X)+VAR(Y) if X and Y are indepenent, otherwise it doesn't hold;
1230 mins, if you add X+X, they are the same, it will magnify the variability;
1502 mins, derive PDF and CDF of a normal that is with offset location and magifiny of sigma
1859 mins, add 2 normal, the distribution is still a normal with miu1+miu2, sigma1^2 + sigma2^2
X1-X2 has exactly the same property;
Not only they have the expected miu and sigma, they are also normal;
68-95-99.7 rule;
2400 mins, another way of writing PMF;
USF, taylor series, euler formula, put it somewhere so taht you can read;
3138 mins, possion has mean lambda, and variance lambda;
geometric dist is an analogous of exponential dist;
3726 mins, symmetry, indicator r.v. , linearity;
3840 mins, product of indicator r.v. is an indicator r.v.
4015 mins, expect I1 and I2 happens, it is just p1*p2;
4109 mins, hyper geo metric, not independent;
4344 mins, proof of LOTUS TBRT;
4458 mins, r.v. is a function that map sample to x;


### Lecture 16 <br>
2022/04/02: ðŸ’« finished, 1144 memoriless propoerty, exponential is the only memoriless distribution; 1704 mins E(X|x>a) = a+E(X-a|x>a) = a + 1/lambda

2022/05/08: 
0200 mins, Exponential distribution, TBR hyper geometric distribution; TBR MGF
0530 mins, Exp(1), Y=lambdaX;
0809 mins, intergration by part;
1132 mins, exponential distribution, memoriless property; binomial waiting in the discrete time, exponential waiting in the continuous time;
1446 mins, survival function, P(X>=s);
1640 mins, exponential prob is the only one memoriless in continuous , geometric is the only memoriless in discrete;

### Lecture 17 <br>
#### REX 1 2022/04/02
#### REX 2 2022/07/22

2022/07/22:

End minus 15 min<->End

- update use bayes rule
- laplace rule of succession
- find posterior 
- p is r.v. in this case
- |p means treating p as constant
- distinguish P and f

2022/07/21:

3148<->4648

- TBRT
- by LOTUS, we get the MGF of normal distribution

2022/07/20:

1648<->3148

- 1730 mins moment generating function
- M(t)=E(etX)
- taylor series, take derivattive and set it as 0, cef of t^n/nfactorial
- SIGMAx^nt^n/nfactorial
- real analysis, and infinite sum
- MGF determines distribution
- independent, you can split the product
- bernp, MGF
- and thus binomial

2022/07/19:

0000<->1648

- geommetric and exponential,  both memoriless distribution in discrete world and continuous world
- aha moment is a memoriless case
- proof of exponential is the only memoriless in continuous case
- TBRT
- G(m/n t)
- G is continuous so you can swap and function G

2022/03/14: ðŸ’« MGF [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/04/02: 3720/5044, 1:00 mins, conditional probability; 910 mins, prove the uniqueness of exp memoryless property; 2238 finite sum is applicable for linearity, infinite sum need to take course real analysis; 2430 mins, interpretation of MGF; 2630 mins, MGF determines distribution; 3018 mins, MGF of X+Y, make X+Y to be easier to be detected; 3500 mins, normal MGF; M^(n)(0)=E(X^n) ; R.V. X has MGF M(t) = E(e^tx)

2022/05/08:
0000<->3000
0129 mins: conditional probability is probability, conditiaonal expectation is expectation;
0247 mins: bias answer;
0455 mins, memoriless property will say, average is 80, when you are 20, then your new E age will be 100
E(T|T>20)=20+E(T), otherwise E(T|T>20) > E(T)
0740 mins, cubic of exponential is a viable
0850 mins, memoriless property is a property of distribution not for a r.v.
0910 mins, if X is a continuous memoriless, then it is a X~Exp(lambda);
I can call myself as librian
1036 mins, memoriless property is G(s+t) = G(s)G(t);
1521 mins, continuous function can swap limit and function, after you take limit, you can make m/n from rational to real number
1800 mins, definition of MGF;
1820 mins, MGF is finite on some interval around 0 otherwise it is not useful, it must be exist to be useful;
2238 mins, if a series is finite, linearity work immediately;
2552 mins, M^n(0)=E(X^n);
2635 mins, MGF determines distribution;
2744 mins, MGF make sum of independent r.v. easy, TBR convolution, TBR C(9,10)=0;


### Lecture 18 <br>
2022/03/14: ðŸ’« MGF [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/04/03: finished, 138 mins moment of inertia; 826 mins benefit of using MGF; 1104 E(Z^n)=0 odd by symetry, normal distribution; 1350 mins geo series converges t<1, taylor series converges everywhere; 2129 mins convolution E(X+Y), take MGF of X * MGF of Y, the result is sum of pois is a pois if they are independent; 2907 mins joint distribution, condition for PMF joint distribution; 4230 mins simple extrem case, analysis method <br>
### Lecture 19 <br>
2022/04/04: finished, 
913 mins, conditional PDF;<br>
347 mins, E g(x,y) by LOTUS;<br>
4100 mins, checken egg problem;<br>
4442 application of law of total probablity;<br>
4600 mins, remove redundancy<br>
### Lecture 20 <br>
2022/04/05: finished,
0000 mins, Ex distance between 2 uniform;
0055 mins, Ex distance between 2 iid standard normal;
independent joint PDF of normal;
0333 mins, MGF applicatioin;
"Know more people", cyber way of interpretation, I got what they say, I store it, I have a map;
0730 mins, easy function;
1600 mins, multinomial;
2150 mins, lumping property;
2600 mins, conditional probability;
3330 mins, cauchy distribution;
3400 mins, symmetry;
4407 mins, u substitution;
4701 mins, LOTP;
4756 mins, independent integration CDF;
### Lecture 21 <br>
#### REX 2 2022/06/14
#### REX 1 2022/04/05
2022/04/05: finished,
2640 mins, dimensionless, unitless;
2959 mins, WLOG, without lose of generality; corr(x,y)=rou;
4200 mins, IA indicator R.V. of event A, IA^2=IA, IA^3=IA, IA*IB=I(A intersect B);
4400 mins, uncorrelated doesn't imply independent;
4800 mins, geometric distribution, use COV formula to prove VAR(X) for geometric distribution

2022/06/10:

0000<->1500

- study 2 RV, is COV
- x,y dependent pair, thus we define COV
- if X=Y then COV formula is variance
- if independent E(XY)=E(X)E(Y)
- use linearity you can rewrite covariance formula to another form
- COV of r.v. and c is 0
- COV(X,Y+Z) use formula and linearity
- bi linearity, treat one variable as constant, then it looks like a linearity for another variable
- it also looks like a distributive property
- play with COV(X+Y,Z+W)=COV(X,Z)+COV(X,W)+COV(Y,Z)+COV(Y,W)
- and a sigma form practice

2022/06/11

1500<->3000

- VAR(X1+X2)
- X1 X2 independent, COV is 0
- VAR(X1+X2+...+Xn), practice to write and arrange i and j and sigma
- X, Y indep, they are uncorrelated COV(X,Y)=0
- converse is false
- odd moment of standard normal with 0 expectation
- Y is a function of X, so Y is dependent of X, X also is a function of Y, at least Y partially determines X
- definition of correlation
- rewrite the function
- WLOG, without lose of generality

2022/06/12

finished,
3000<->End

-  VAR(X+Y) VAR(X-Y)
- proof of correlation is between -1 and 1
- COV i a multinomial, multi dimension of binomial
- competing game
- indicator r.v. to prove the var of binomial
- IAIB = ? intersection
- prove bernuli firstm ten prove binomial
- indicator r.v. practice
- hyper geometric proof

### Lecture 22 <br>
2022/04/06: finished, 
100 mins, hyper geom(w,b,n), withoug replacement binomial;
540 mins, finite population correction;
1101 mins, transformation;
1705 mins, log normal;
2355 mins, jacobian;
2600 mins, convolution - fancy name of sum;
4000 mins +, shenon information theory;<br>

2022/05/05: finished,
0038 mins, hyper geometric;
0220 mins, VAR and COV, expansion of VAR(SIGMA Xi);
0535 mins, finite population correction;
0736 mins, transformation, fY(y) = fX(x)dx/dy, y = g(x), x = g-1(y);
1648 mins, log Normal, don't seperate dx/dy unless you interprete it right;
2115 mins, random vector, n dimension transformation;
2345 mins, Jacobian, TBR, matrix of all possible partial derivative, reciprocal;
2746 mins, convolution, fancy word of sum of random variable;
3212 mins, you can swap derivative and intergral, there is a theory proves that;
3357 mins, probability can be used to prove existence of something that you can't exibht? TBRT (to be reviewed, this);
3916 mins, shennon theory, TBRT;
### Lecture 23 <br>
2022/04/07: finished, 0830 mins conjugate prior;
1049 mins, bayesian statistics;
1620 mins, laplace therom;
2300 mins, doing calculus without calculus;
2602 mins; finance STAT123 course, the same as the teacher in MIT finance math course;
3320 mins, F(R.V.) is a R.V.;
4400 mins, TARP;
4200 mins, FX problem puzzle
2022/04/24: finished, 0225 mins, generalized uniform is beta, bounded by 0 and 1, not flat, beta(a,b), a>0,b>0;
0728 mins, conjugate prior to binomial;
1053 mins, X is observed data, X|P ~ Bin(n,p), P~B(a,b) - prior;
laplace?uniform?;
f=PDF;
1604 mins, interesting explaination of beta;
1741 mins, 1st moment beta, 2nd moment still beta;
nomalizing constant;
2023 mins, bayes billiards;
2415 mins, PDF of uniform is 1;
4420 mins, warrant = call option;
4725 mins, strike price;
4825 mins, LOTUS;

2022/06/01:

0000<->1628

0000 mins

- beta distribution
- integral get beta function
- conjugate prior to binomial
- prior, posterior
- TBR E calculation and COV calculation
- propotionality, why propotionality can work, OK, because constant is just to make integration of PDF to be 1
- 

1500 mins

2022/06/02:

1500<->3000

1500 mins

- story proof

3000 mins

2022/06/03:

finished,
3000<->End

3000 mins

- g(ST), ST is a stock of a company, g is a derivative
- think probability and distribution, then you will think about how much you will pay in the end E(g(ST))
- binormial, bi-variate normal
- warrants = call option, is a derivative
- blackshoes formula

End mins

### Lecture 24 <br>
#### REX 3 2022/07/09
#### REX 2 2022/04/25
#### REX 1 2022/04/08
2022/04/08: finished, 0530 mins, sterling formula;
1133 mins, Gama function factorial formula;
1733 mins, normalizing constant of normal;
3600 mins, MGF proff gama distribution;
2150 mins, transformatijon Y=X/lambda;

2022/04/25: finished, 0600 mins, sterling formula;
0818 mins, gamma function is important;
1305 mins, intergral from 0 to infinity 1/e^x dx = 1;
1420 mins, intergration by parts;
2000 mins, Gamma(a,1), Gamma(a,lambda);
2130 mins, transformation;
2300 mins, Gamma related with many distribution;
2800 mins, memoriless property, poisson & exponential;
4256 mins, LOTUS

2022/07/06:

0000<->1500

- arithmatic sequence
- gamma 1/2 is sqrt(pi)
- normalizing normal, also has something to do with sqrt(pi)

2022/07/07:

0000<->1500

- understand the approximation and limitation
- gamma distribution came from game function
- more integration is needed
- the relation between gamma and integration
- 

2022/07/08:

1500<->3000

- normal formula, and the difference between the two
- how to turn a formula to PDF, normalize
- Gamma(a,lamda), Gamma(a,1)
- poisson processes
- disjoint, joint intervals
- 2800 mins, poisson and exponential
- interarrival times are iid expo(lambda)

2022/07/09:

3000<->End

- negative binomial & geometric
- convolution
- list all the distributions
- induction
- MGF
- to understand this part, MGF, convolution, negative binomial, geometric, posson and exponential
- TBRT
- 4700 mins, the property of gamma function
- Gamma(a,lambda), what does the lambda mean

### Lecture 25 <br>
2022/03/29: ðŸ’« 432/4814, suddenly want to back to basic stuffs <br>
2022/04/09: finished, 332 mins, Beta Gamma, need to review previous 2 videos; transformation function;
900 mins, jacobian, take determinant, take absolute value;
1320 mins, independent definition;
2252 mins, independent E(XY)=E(X)E(Y);
2900 mins, order statistics dependent; Fx CDF fx PDF;
4230 mins, relation of order statistics and beta;
4523 mins, E(X) = E(X|A)P(A) + E(E|Ac)P(Ac) and its proof, using LOTP;
4642 mins, envolop paradox, the same as the movie 21 points said;
### Lecture 26 <br>
2022/04/11: finished, 0300 mins LOTP;
2100 mins, partial progress;
2320 mins, iteration of Ew HH;
2700 mins, ted peter donnelly;
3400 mins, g(x)=E(Y|X=x), E(Y|X)=g(X);
3600 mins, eg E(Y|X)is a r.v.
### Lecture 27 <br>
2022/04/13: finished,0120 mins, best minimize mean square error is the purpose of E(X|Y)
0600 mins, E(Y|X=x) is function of x;
0900 mins, E(h(x)Y|X)=h(x)E(Y|X) taking out what's known;
E(Y|X)=E(Y) if X Y are independent
E(E(Y|X)) = E(Y) adam's law;
E((Y-E(Y|X))hx)=0, residual, uncorrelated;
1900 mins, using plain to understand E(Y|X)
2700 mins, re-arrange term and summation;
3300 mins, VAR(X|Y), EVE's Law;
3700 mins, add variance, just like Chi square
### Lecture 28 <br>
2022/03/14: ðŸ’« Che inequality [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/04/11:  0000<->0830, 0500 mins, category error;
0727 mins, LOTP;
0830 mins, Adam's law; <br>
2022/04/13: finished, 1700 mins, how to argue in a court;
1900 mins, cauchy-schwarz E(XY) analogy to dot product;
2100 mins, 2D LOTUS; Jension inequality
2816 mins, E(g(X))>=g(E(X)) <- EX^2 >= (EX)^2, because VAR can't be negative;
3738 mins, fundamental bridge;
4345 mins, chebyshev; <br>
2022/05/04: finished, 700 mins, EX=sigma E(X|N)P(N);
0830 mins, adam's law E(X)=E(E(X|N)) E(X|N) means treat N as known;
1034 mins, Var(X) = E(VAR(X|N)) + VAR(E(X|N)) Eve's law;
1300 mins, MGF, TBR MGF,  sigma X = PI MGF of each X;
1900 mins, cauchy schwarz inequanlity, intuitively means corr<=1, it shows correlation how it looks like when miu = 0;
when X and Y uncorrelated, E(XY) = E(X)E(Y);
2412 mins, Jension inequality, g is convex E(g(x)) >= g(E(X)), EX^2 >= E(X)^2 intuitively understanding;
3446 mins, Markov inequality, use bridge indicator;
4100 mins, intuition of Markov;
4200 mins, chebyshev
### Lecture 29 <br>
2022/03/14: ðŸ’« Che inequality [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/04/13: finished, 0312 mins, LOLN;
1800 mins, degenerate distribution;
3300 mins, by definition;
3900 mins, factorial grows too fast;
4100 mins, appromximation;
4330 mins, fundamental theory CDF - CDF = PDF;
4600 mins, n large & p, pois converge to normal

### Lecture 30 <br>
2022/04/14: finished, 0141 mins, chi square n, chisquare 1 -> take 1 N(0,1) is Gamma(1/2,1/2), chi square n is Gamma (n/2,1/2),
0816 mins, Gosset 1908 student-t;
1337 mins, Cauchy and student t;
2500 mins, LOLN;
2905 mins, MVN;
3000 mins, Random vector;
ind->uncorrelated, uncorrelated!=>ind for univariate, while it seems work for multi-variate
COV(X+Y,X-Y)

### Lecture 31 <br>

#### REX 3 2022/06/25
#### REX 2 2022/05/03
#### REX 1 2022/04/15

2022/04/14: 0<->1928, 0430 mins, stochastics process;
0730 mins, 171 class stochastic process;
1928 mins, lost interest for today <br>
2022/04/15: finished , 1920<->End
2230 mins, Markov monte carlo;
2600 mins, Markov story;
4000 mins, stationary;<br>
2022/05/03: finished, 0346 mins, TBR ineuality;
0519 mins, stochastic processes, X0 X1 X2 with some dependence, one step beyond iid;
0732 mins, cont/discrete time, cont/discrete space
1049 mins, Markov property;
1159 mins, past future, conditionally independent, given the present;
1358 mins, homogeneous, qij independent of t;
2333 mins, Markov chain, converge to a distribution you are interested in, this is MCMC Markov chain monte carlo, build your own MC, TBR fourier;
2641 mins, LOLN hold on iid, free will, LOLN hold in Markov;
3300 mins, LOTP;
4000 mins, stationary, steady state, converge, $\vec{s}$$Q$ = $\vec{s}$, also it is eigen value and eigen vector

2022/06/23

0000<->1500

- chronological
- markov chain, example of stochastic processes
- discrete r.v. and discrete space
- think about continuous r.v. and continuous space
- P(xn+1=j|xn=i,xn-1=xi-1...)
- past and future are conditionally independent given the present
- homogeneous, qij this doesn't depend on time, that means there are some qij depend on time

2022/06/24:

1500<->3000

- transition matrix, stationary property
- markov chain to simlulate something
- LOLN holds in Markov chain case as well
- 1 by M matrix is a vector
- the reason that he uses vector times Q is because of the way he define Q, his Q is on row wise not column wise

2022/06/19:

3000<->End

- he also use row vector, 1 by M vector
- Xn and,  s vector PMF at time n
- s is 1 by M matrix, Q is M by M matrix
-  does it exist, is it unique, stationary dist is referring s vector


### Lecture 32 <br>
#### REX 1 2022/04/16 
2022/04/16: finished, 0640 mins, irr irreducible, you can go anywhere from anywhere;
0812 mins, recurrent, start at a state return to a state; otherwise, transient;
1330 mins, absorbing state;
2230 mins, Markov chain, si=1/ri, ri start at i;
2700 mins, prob vector;
2930 mins, reversible markov chain;
4500 mins, proof of chain, qij=1/di

2022/06/21

0000<->1540

- irreducible chain means you can go anywhere from anywhere
- the opposite is reducible
- reducible can be split to irreducible
- state is recurrent, P =1 of returning to that state
- the opposite is transient
- 1300 mins a case of turning a recurrent structure to transient
- 1400 mins a case of recurrent and transient mix, also a visualization of gambler's ruin
- periodic chain
- 1540 mins summary

2022/06/22

1500<->3000

- s vector is stationary with trans matrix Q
- OK, TBR lecture 31
- TBRT why it is unique
- still TBR markov chain
- reversible MC TBRT

### Lecture 33 <br>
2022/04/16: finished, 1700 mins, Markov chain - google;
2000 mins, google story;
3600 mins, teleportation = fancy word of not follow the hyperlink's instruction, google set the threshold as 0.85
### Lecture 34 <br>
2022/04/15: finished, 0730 mins, probability model->data, inference data->parameter;
1940 mins, mostly harmless econometric book
