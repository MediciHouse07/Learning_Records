https://www.youtube.com/watch?v=KbB0FjPg0mw&list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo

# Lectuer 29

2025/12/20

0000<->1000

- either converge or not is an event
- i.i.d assumption be careful not to drop it. you can improve the distribution

# Lecture 6

2024/12/17

3500<->4500

- adding fraction type of reasoning
- confounder
- given dr. hebert is conducting a surgery, you know
- RECORD_WEIGHT_165.4

# Lecture 6

2024/12/16

2500<->3500

- can flip, one thing seen better than another on every individual case, but it may flip the result

# Lecture 6

2024/12/15

1500<->2500

- prob problems, you can say I wish I knew this or that
- LOTP
- Asymmetry, symmetrical
- computer simulation to prove it
- extreme case 100M door analogy

# Lecture 6

2024/12/14

0000<->1500

- 165.9
- least possibilities correct rate check
- tree diagram, intuitively, conditional argument

# Lecture 5

2024/12/13

4000<->5000 End

- independence vs conditional independence
- chess opponent of unknown strength
- seemingly
- given the strength of opponent
- 165.9
- without conditioning on fire alarm goes off, independent, with the condition, dependent

# Lecture 5

TBRT

2024/12/12

4000<->5000

- may or may not be
- earlier, later outcomes

# Lecture 6

3300<->4300

2024/12/11

- common situation
- 166.0
- shortly after
- trama
- put you in touch with him
- prior P(A), posterior P(A|B)
- independence, conditional independence

# Lecture 5

2024/12/10

1800<->3300

- TBRT start 2800
- coherence
- evidence get in one step or separate steps would return the same result
- prosecutor's fallacy, defensive aterney

# Lecture 5

2024/12/09

0500<->2300

- LOTP
-afflict

# Lecture 5

0000<->0500

2024/12/08

- extreme cases
- break up problem into simpler pieces

# Lecture 4

3400<->4900 End

2024/12/07

- assume finitely many outcomes, don't assume they are all equally likely
- on a roll, good luck or moving towards positive

# Lecture 4

3000<->4500

2024/12/06

- event is a subset
- technical difficulty, renormalize
- make the total mass one
- pebble world vs frequentist world
- repeat expt many times, be challenged by philosophy world

# Lecture 4

2024/12/05

1500<->3000

- pepys, Samuel pepys
- binomial derived
- it is confusing, and confusing intuition
- would be invariant

# Lecture 4

2024/12/04

0000<->1500

- all subset of size k
- MEIGHT 164.4
- very likely versus some many chances resulting in 1/e
- two computing forces
- when n goes to infinity or very big number

# Lecture 4

2024/12/03

0000<->1000

0400<->0900

- inclusion and exclusion

# Lecture 3

2024/12/02

3800<->4800 End

3800<->4300

-at least one match

# Lecture 3

2024/12/01

3800<->4800 End

- deMontmort's problem 1713, matching problem
- looks messy
- n choose 2?

# Lecture 4

2024/11/26

0000<->1000

- TBRT
- TBR the end of last lecture

# Lecture 14

0000<->1000

2024/10/04

- scale

# Lecture 14

2024/10/03

0000<->1000

- third moment, because it is odd function, thus it is 0
- translate standard normal into general form
- desired mean and variance
- has no effect
- variance violate linearity property

# Lecture 13

4000<->5109 End

2024/10/01

- odd function
- integrate a function on a symmetry domain
- even function
- twice the area from 0 to infinity
- one piece is easy to integrate, another part is easy to differentiate
- let z be u, bundle as dv
- should be a minus sign in front
- integrate udv = uv- integrate vdu
- TBR integration by part
- notation clashing

# Lecture 13

2024/09/30

3000<->4000

# Lecture 13

3000<->4000

2024/09/29

- double integral
- is it good if we change z into x and y
- jacobin and mathematic handout
- TBRT

# Lecture 13

2024/09/28

2000<-3000

- it's not fair to credit him
- there are many reason for that
- CLT, add up any i.i.d rv, it could be discrete the distribution looks like normal

# Lecture 13

1000<->2000

2024/09/27

- solve for inverse function, x interms of y solve for y interms of x
- generate 10 i.i.d uniform, and fill in the function and that is 10 events from F, the simulated distribution
- linear transformation on uniform is still uniform for some interval
- understand independent
- you can actually prove the above computer simulation case, and check its CDF
- definition of independent
- event versus random variable
- that definition is for all, behind it is not only one equation
- joint PMF
- joint CDF
- in discrete case, the two equations are equivalent
- knowing value A, does not provide any info about another value B, there are a lot of independence analogy in the real world

# Lecture 13

2024/09/26

0000<->1000

- valid point
- at the end last time
- continuous, strictly increasing CDF
- take R.V. X and put it into its own CDF then it is unif 0,1
- CDF is always 0,1; but it is not always unif
- X<=X is an event that always happen
- understand more of x and X
- evaluate a function as a function, then substitute X in it

# Lecture 13

0000<->0500

2024/09/25

- 2024 minus 11 = 2013, UK judge decide not to allow Bayes rule being used in court
- universality of uniform, cont.
- in general CDF can be flat in region
- synthetically

# Lecture 12

4500<->5000 end

2024/09/25

- 162.4
- universality of uniform, have CDF find R.V. that have that CDF
- let X=F-1u
- then statement is X~F
- need to check how R.V. and CDF if and only if conclusion is drawn
- the relation is preserved

# Lecture 12

2024/09/24

3000<->4500

- real numbers, every point has probability zero
- probability is proportional to length
- density is c
- and it has to pass sainity check
- unif CDF, branched way in expressing its formula
- and continuous checks on the key points
- function of random variable is a random variable
- change big X into little x
- one third, one quarter
- universality of uniform

# Lecture 12

2024/09/23
1500<->3000

- std is more interpretable
- variance has many nice property, and it is nice to work with
- EX^2=E(X^2)

# Lecture 12

2024/09/22

0000<->1500

- continuous distribution
- analygous discrete vs continuous
- f is not probability, density is not mass
- integral f is probability, density times length is mass

# Lecture 11

2700<->4200 End

2024/09/21

- a measure of intensity
- X be number of triple matches, P(X=k) is probability of 
- large number of triple matches, and the likely is very small

# Lecture 11

1500<->3000

- a lot of people could email, but for any particular person it is unlikely to email you at certain time point
- first choice distribution
- paradigm, approximation
- a tiny bit likely, more likely
- by linearty, lambda is sum of pjs
- limits kick in
- p goes to 0 at the same rate n goes to infinity
- separate it out
- k terms
- LBT rule and compounding interest rate

# Lecture 11

2024/09/18

0000<->1500

- e to the lambda comes out
- a function of R.V. is R.V. right? to confirm

# Lecture 12

2024/09/17

0000<->1500

- to understand CDF
- word is not the thing, map is not the territory
- R.V. is the house, distribution is blue print

# Lecture 12

3500<->5000 End

2024/09/16

- E of X square
- to get E of Y, you need to know PDF of Y
- half asleep
- fX(x)
- LOTUS for discrete X is also valid
- unif 0,1 is one twelth
- universality of uniform
- why random uniform can simulate
- we know CDF, but we don't have access to know its PDF
- strictly increasing enable inverse exist
- X~F means X has CDF F
- increasing function doesn't care inverse of inequality

# Lecture 12

3000<->4500

2024/09/15

- unif, probability is propotional to length
- fx=c it doesn't say c has to be within some intervals
- c=1/b-a
- expectation of uniform
- Y=X^2, PDF of Y
- LOTUS, law of the unconscious statistician
- TBRT shift 5 mins

# Lecture 12

1500<->3000

2024/09/12

- if we know the relation, F and integral f, how to scrap out f, it is simply taking derivative by FTC2
- strict and non-strict
- variance, how far X is away from its mean
- expand it out, and multiply it out
- Ex^2 is always greater than or equal to Ex^2
- equality hold when it is constant

# Lecture 12

0000<->1500

2024/09/12

- for the purpose of the picture
- function is greater than 1, but area can still be integrated into 1
- continuous means x can take continuous values
- reverse direction of FTC2
- FTC2 derivative of CDF is PDF

# Lecture 12

0500<->2000

2024/09/02

- I could have said
- F to be continuous 
- FTC
- I take derivative , II want to calc definite integral
- assuming derivative exist

# Lecture 12

0000<->1500

2024/09/01

# Lecture 11

3200<->4200 End

2024/08/31

# Lecture 11

2024/08/30

2200<->3200

- whether it gets dropped with a rain

# Lecture 11

2024/08/29

1200<->2200

- a lot of persons could email you
- any specific person could email you
- a lot of raindrops
- less likely a little box would meet a raindrop

# Lecture 11

0000<->1200
+3mins review

2024/08/28

- different r.v. can have the same distribution
- r.v. is the house, distribution is the blue print

# Lecture 11

2024/08/24

3500<->4200 End

- unlikely
- and weakly dependent

# Lecture 11

2024/08/26

2500<->3500

- 3000 mins binomial converge to poisson
- huge number of square, for each square the rain drop is less likely
- scientific computation difficulty when handle it in binomial, but poisson is more helpful

# Lecture 11

1500<->2500

2024/08/25

- poisson paradigm, poisson approximation
- A1, A2, ... An, n is large, weakly dependent, pj is small
- when p is the same, then it is binomial np
- poisson can take different probability

# Lecture 11

2024/08/24

0000<->1500

- sympathetic magic, distribution and R.V.
- adding r.v. doesn't mean adding PMF
- distribution, PMF is blueprint
- R.V. is one of the house
- binomial is bounded by n
- poisson doesn't, it has k 0 union N
- taylor series starting from 0
- just to have a word

# Lecture 11

2024/07/31

2000<->4200

- pois is a approximation
- binomial np converge to poisson
- when n is large, p is small
- holding the product np = lambda constant
- definition of e to x, compound interest
- independent and exactly binomial p, then you can use binomial
- and assume 0 and 1 as value of random variable
- # triple matches
- lambda is known 
- X = ? in the poisson formula means number of matching tripplets
- E(X) where n choose 3 is not related to ?

# Lecture 11

0000<->2000

2024/07/30

- sympathetic magic
- adding R.V. is not the same as adding PMFs
- R.V. house, distribution blueprint
- 0500 mins, random house, doesn't specify to put a door over where
- poisson distribution 0630 mins
- it is a discrete distribution
- PX=k = e(-lambda)lambda(k)]/k!, k=0,1,2
- 0830 mins, sanity check
- 1300 mins, application of poisson
- define success and failure
- large number of trials, each one of being success has a less probability
- large number of trial, small probability of success
- make up as many examples as you want
- pois paradigm/approximation
- poisson paradigm can take independent and weak dependent

# Lecture 10

2500<->5000

2024/07/30

- convention
- first success distribution 2700 mins
- time util the first success
- Y is geometric P
- 2900 mins, intuitive way of thinking the first time success
- number of local maximum
- random permutation
- intermediate point and end point
- 3900 mins, St. Petersburg paradox
- head first trial two dollar
- second four dollar
- third eight dollar
- and so on
- what price could make the expectation to be 0, fair price
- to be sorted out
- you can use linearity on even infinity case, but you can't move E to the power part

# Lecture 10

2024/07/29

0500<->2500

- sum over x, sum over y
- versus sum over pebbles
- negative binomial is a generalization of binomial
- number of failures before rth success
- r success,p probability of being success
- n failure
- before, between x and y
- geometric can start from 1, it can also start from 0

# Lecture 10

2024/07/28

0000<->0500

- expectation doesn't exist, divergent
- a proof on linearity

# Lecture 9

2024/07/28

2500<->5000

- indicator r.v.
- E(X)=P(A)
- 2900 mins, choose president story
- j=k-1
- k=j+1
- 3200 mins, linearity
- E(X+Y) = EX+EY even if X and Y are dependent
- a lot of work
- 4100 mins, geometric
- # failures before the first success
- sainity check for geometric series

# Lecture 9

2024/07/27

1000<->2500

- increasing, right continuous, fx-0 x->-infinite
- if and only if, secure CDF
- independent CDF
- geometric series, times
- arithmetric series, add
- 1 1 1 1 3 3 5 5 5
- weighted average, unweighted average
- high weight for event that is more probable to happen

# Lecture 9

0000<->1000

2024/07/26

- little x is defined on real x
- PMF non negative, and can add up to 1
- CDF is entire distribution
- axiom of probability 0600 mins
- CDF F
- properties of CDF, increasing, right continuous, Fx->0, as x-> minus infinity and vice versa

# Lecture 8

4000<->5000 End

2024/07/26

- n choose k, k>n the choose is 0
- Hypergeometric distribution 4400 mins
- k is from 0 in hypergeometric
- in some cases were n is extreamly big, hypergeometric can be approximated to binomial
- otherwise it wouldn't be added up to 1
- proof for the vandermonde for the third time
- 4830 mins, help you to think why the CDF as the <= sign instead of another direction
- continuous CDF can take negative number, discrete CDF can only take positive number

# Lecture 8

2024/07/25

2000<->4000

- add two functions, in the same domain
- compute both functions and add value then you have new functions
- function of random variable is random variable
- sum of n+m i.i.d
- 2550 mins convolution
- LOTP how to write it correctly
- =j
- sum up to k
- independent means we know something doesn't give additional information on another
- meas you can cross the given part
- p to the k is not dependent on j, taking it out
- vandermonde 3000 mins
- 3200 mins second proof of vandermonde identity
- squicky
- X=#aces is a function

# Lecture 8

0000<->2000

2024/07/24

- a family of binomial distribution
- n independent ber p trials, p is probability of success
- sum of indicator variables
- sum of indicator variables which are formed by bernouly p
- i.i.d tell you even the r.v.s have the same distributions, but they can still be different r.v.s think about binomial distribution
- r.v. is a function, assign number to elements in sample sapce
- X=7 is an event
- X<=x is an event
- Fx=PX<=x
- CDF is also a representation of distribution
- two sanity checks, p>=0 sum p =1
- binomial therom (p+q)^1; k start from 0

# Lecture 7

4100<->5100 End

2024/07/23

- randomness comes from experment
- then map the event to a real number
- Defn Bernoulli distribution
- map to 0 or 1
- X=1 is an event
- binomial n,p
- map to 0 1 2 3 N
- distribution, what is p X=1 what is p X=2
- distribution is P(X=k)

# Lecture 7

2024/07/22

2500<->4100

- take a limit to the unfair game solution
- find it surprising
- as x is going to 1
- TBR LPT
- 3300 random variable start
- differentiate events
- A B C for amount x y z, events way of denoting, running out of notation
- 3500 trying to interpret random variable
- what is variable
- x is a symbol stands for a number
- he didn't explain what is variable
- but he is going to explain what is random variable
- R.V. is a function from sample space to R
- reconcile
- think of as the numerical summary

# Lecture 7

1700<->2500

2024/07/21

- start by guessing a power, for index like term
- repeated root
- explicit solution, recursive solution

# Lecture 7

2024/07/20

1000<->1600

- it seems p and pi are not the same, pi is the target, p is the chance of wining each individual round, pi is the chance of wining the game starting in i

# Lecture 7

1000<->1500

2024/07/18

- first step analysis
- TBRT

# Lecture 7

2024/07/17

0000<->1000

- 0247 gambler's ruin problem
- B is "ruined" aka bankruptcy
- 0700 mins random walk
- absorbing state

# Lecture 4

2024/07/16

0000<->1000

- the first k are constraint and only can have one order
- at least one match and no match
- complement
- competing forces end in 1/e

# Lecture 3

3500<->4900

2024/07/15

- deMontmort's matching problem
- 1713
- infaintcy
- taylor series, 1-1/e

# Lecture 17

3700<->4700

2024/07/14

- laplace rule of succession
- prior, posterior

# Lecture 17

2024/07/13

2700<->3700

# Lecture 17

1700<->2700

2024/07/12

- bookkeeping device
- exist on some internal, finite version of linearlity, we don't know if linearlity valid on infinite case
- take nth moment evaluate at xx
- same MGF determine the same distribution, CDF and so on

# Lecture 17

2024/07/11

0700<->1700

- memoriless is the property of the distribution
- a proof that exponential is the only continuous memoriless function


# Lecture 3

2500<->3500

2024/07/10

- axiom 0, probability is within 0 and 1
- disjointification
- wishful thinking and questionmark

----


35 lectures in TTL
### Questions: <br>
PDF PMS CDF, always forgot the difference between them
### Lecture 1 <br>
#### REX 1 2022/02/20
#### REX 2 2022/08/13

2024/06/22

3500<->4600

- 0 if k >0 n choose k example
- with replacement, without replacement
- replacement or not vs order matter or not
- with replacement and order doesn't matter

2024/06/19

2500<->3500

- life 1/2
- intelligence life 1/2
- counting multiplication rule

2024/06/18

1500<->2500

- number of favorable outcomes
- number of possible outcomes
- circularity

2024/06/17

1500<->2500

- sample space is the set of all pissible outcome of a experiment
- an event is a subset of sample space
- think events as subset is  a breakthrough
- number of favorable outcome

1000<->1500

2024/06/16

- applied statistics on political science
- IQSS
- fermat pascal 1650
- develop the subject gambling
- logic of certainty, logic of uncertainty
- quantifying uncertainty

2023/08/29

3000<->End

- ice cream, cone and flavor
- replacement, order matters

1500<->3000

2023/08/28

- think event as subset
- number of favorable outcomes with respect to A
- Naptune
- naive definition with no justification

2022/08/13

3000<->End

- 3600 mins, if k>n = n choose k 0, n choose k (n k) = n!/n- k!k!
- proof of n choose k
- think in terms of multiplication rule
- 4300 mins sampling table

2022/08/12

1500<->3000

- experiemnt can be anything, you do something, something happens
- sample space, is all possible outcomes of an experiment
- event is a subset of the sample space
- 2148 mins, naive defn of prob, P(A)=#favorable outcomes, favored by A/# possible outcomes
- assumes all outcome are equally likely, finite sample space
- for example, if there is alien, mistakely using naive definition if 1/2
- 3100 mins, multiplication rule

2022/08/10

0000<->1500

- 0646 mins, naive definition of probability
- last time? it seems there is another course before this course
- Mosteller, founder of stats institution in harward
- Govt IQSS, politics and stats probability come together
- Gambling game, Fermat, Pascal, 1650, letters
- math is logic of certainty, statistics is logic of uncertanty
- 1500 mins, naive definition

2022/02/20: finished
### Lecture 2 <br>

#### REX 2 2022/08/22
#### REX 1 2022/02/23

3500<->End

2024/07/06

- this sum collapse to that sum
- vandermonde
- 4000 non-naive probability
- not assume equally likely outcome
- probability space, sample space
- S P
- P take S as input, sub set of S, event
- [0,1]
- P(empty)=0, P(S)=1
- empty set to occur, want impossible event occur
- tautology
- two axioms, countbly infinite sum

2500<->3500

2024/07/05

- overcounting
- story proof for, pick k people to maintain generality, president and club game
- multiplication rule
- if the both ways are correct, they must agree

2500<->3000

2024/07/04

1500<->2500

2024/06/30

- x choose y
- n object, k times, with replacement, order doesn't matter
- put k indistinguishable particles into n distinguishable boxes
- how many  ways, and n choose k
- physics problems behave like non-label case

0600<->1600

2024/06/29

- 0!=1 choose 0 is also 1
- n-1 choose n is 0

2024/06/28

0800<->1800

- subtle distinction of choose 4 out of 10 and choose 5 out of 10
- it's mysterious where it comes
- not to choose is one option
- n-1 choose n is 0, you can't choose n because there is not enough people

2024/06/27

1000<->2000

- simplest non-trivial examples
- trivial examples but worth of checking

0000<->1000

2024/06/23

- no calculator is needed
- is written on them

0000<->1500

2024/03/01

- 52 choose 5, self annotating, let you know what this big number represents
- I am stressing this
- 10 choose 4
- 2 teams of 5
- naive definition
- frame it in the right way, you can use naive definition
- follow my own advice
- TBRT SHIFT 5

0000<->1500

2024/02/28

- fraction
- plug in simple and extreame cases
- get confused
- tell them apart
- I could have said
- 10!/4!*6!
- how many way you can order them

2023/11/21

1500<->3000

- nontrivial
- equivalent expression
- n=4 k=6
- as a contrast to labelling
- TBR This lecture

2023/11/20

1500<->3000

- put indistinguishble particle into distinguishble box
- TBRT
- encode it in different ways
- over counting
- bizarre

2023/11/19

0000<->1500

- self annotating
- labelling
- circumstance
- labelling vs 10 choose 5
- naive definition, assume equally likely outcome

2023/11/18

0000<->1500

- self annotating
- TBRT
- 2 teams of 5
- have double counted it
- choose 0 is 1
- one way to do it, which is not to choose it

2022/08/22

3000<->End

- proof by interpretation
- vandermonde 3618 mins
- 4300 mins, non naive definition of probability
- S is a sample space, P(S)=1, S is the whole universe
- are disjoint

2022/08/21

1500<->3000

- different way to represent the same situation, such as put dots in different boxes, or using a bar between different groups of dots

> The beauty of math is, you can simulate a result of a thing, without really using material
> Hi history me, sitting on a coach, wearing a heavy clothe to keep warm, in the mid night, watching this video

2022/08/20

0000<->1500

- self annotating
- 10 people, split into team of 6, team of 4
- and 2 teams of 5 are different
- n-1 choose 0 is 1, only way one to choose that is not to choose, n-1 choose n is 0, because you can't choose n from n-1

2022/02/23: finished
### Lecture 3 <br>

1500<->2500

- one day apart
- full samples space is an event that always occurs
- second axioms is true require Ai...An are disjoint events
- continues in these days, of axioms of probability, in other subjects, philosophy, physics
- sainity check for if a probability is a probability

2024/07/07

0000<->1500

- birthday problem
- Dec 30 1st
- pigeonhole principle
- approximate birthday no match to exponential
- futile
- unobjectionable

2022/09/02

3000<->End

- wishful thinking
- matching problem & taylor series, TBRT

2022/09/01

1500<->3000

- drink milk in the morning
- disjoint events
- if A<B then P(A)<P(B)
- proof of P A Union B

2022/08/30

0000<->1500

- birthday problem
- pigeonhole principle
- store information in computer science
- 23 people will give 50%
- 50 people will give 97%

2022/02/24: 1219/4854 birthday problem<br>
2022/03/24: finished, the last problem is hard, I might need to listen the question again, and has something to do with taylor series, 1-1/e
### Lecture 4 <br>

0000<->1000

2024/07/08

- matching, inclusion exclusion
- geometric series, taylor series e to the x
- discret problem was transferred to continuous problem in the form of e to the x
- pessimist, optimist

2022/09/25

4500<->End

- n factorial THMs

2022/09/24

3000<->4500

- conditional probability, evidence added
- conditioning is the soul of statistics
- a notebook, that can be used to seach all my words
- dependent and independent
- intuition brain and logical brain
- if conditioning on B, then B is the only universe, the B complementary is excluded
- renormailize
- intuition 1 and intuition 2
- pebble world and frequentist world
- 4421 mins, example of frequentist world

2022/09/23

1500<->3000

- independence, conditional probability
- Newton pepys problem
- assumption makes naive definition applicable
- SIGMA binomial probability

2022/09/22

book page 25<->26

- Reviewed the part in the 20220921 study in the book de Montmort matching problem

2022/09/21

0000<->1500

- matching problem
- jth card in deck is labeled j
- maybe need to review the book to get a concrete idea of it
- e to the x evaluate at x equal minus 1
- 2 computing forces end in 1/e
- next step is to define independence

2022/09/20

0000<->1000

- by symmetryc, subscript can be anything
- 0400 mins, probability and conditional probability
- symmetry is the key to this section
- this is also an application of inclusion and exclusion
- the card you name is the card that appears, but it can think in another way, the deck is randomly arranged
- how to interprete P(U A)? why the formula strart with 1 - 1/2! ...
- OK, it might be the probability of matching 1 2 3 4, and the opposite is probability of no match
- only intersection of A complement can be think of as exactly no match, otherwise it has at least one match

2022/09/19:

0000<->1000

- by inclusion and exclusion
- matching problem is in the end of the last lecture
- add P and subtract P for intersection
- the first k is labbeled
- didn't follow, something were forgot
- complement of a union is intersection of a complement
- taylor series e^x
- TBRT

2022/03/26: finished, the begining of this lecture has a continue relation with the end of Lecture 3 <br>

### Lecture 5 <br>
#### REX 1 2022/03/31
#### REX 2 2022/08/03

2022/10/09

3500<->End

- prior before we have the evidence, posterior after we have the evidence
- PA prior, PA|A posterior
- chess opponnent of unknown strength
- condition on how strong the person is, all the game are independent; not condition on how strong the person is, ealier game gives you evidence so not independent
- 4708 mins another direction of indept and dept
- fire alarm example
- indept F and C, but it would be dependent given A

2022/10/08

3000<->4500

- with the new evidence, update the probability
- bayes rule has coherence property
- probability and law, example 3500 mins
- include independence thinking and bayesian thinking
- prosecutor fallacy
- statistical science in a court room, statistics for a lawer 2 books recommendation
- prior, postererior
- PA is not one, PA|A is one
- confusing independence with conditional independence 4107 mins
- CI given C doesn't imply independence

2022/10/07

1500<->3000

- specify the type of the ace, the probability doubled
- counter intuition
- 2100 mins another example about conditional probability
- 2252 mins, intepretation of the assumption
- what patient cares about
- an example of using LOTP makes problem easier
- 1%, 95%
- second test is not independent
- competition between how rare a disease and how are a wrong test
- frequentist

2022/10/06

0000<->1500

- simulation game
- measure uncertainty
- pie and incorrect evaluation
- break up problem into simpler pieces
- partition = disjoint and complete the whole picture
- 0722 mins, law of total prob
- 0944 mins, example of LOTP
- ace of spades
- stops at the second question of the example

2022/08/03:

3100<->End

- intersection of clue, or one after another one will end up with the same probability
- innocent given evident, evident given innocent
- 3800 mins statistical science for the court book
- prior, posterior
- indep and conditional indep
- conditional indep doesn't imply indep
- 4900 mins indep doesn't imply conditional indep

2022/08/02:

1600<->3100

-  demographic
- disease and test
- 2442 mins bayes rule and LOTP
- rare of disease and rare of test is wrong, both matters

2022/08/01:

0000<->1600

- decompose smaller pieces
- 0700 mins LOTP
- 2 poke card example
 
2022/03/30: 1907/5001 law of total probability, conditionging<br>
2022/03/31: finished, conditioning independent doesn't imply unconditioning independent and vice versa
### Lecture 6 <br>

#### REX 2 2022/10/30

2022/10/30

3000<->End

- conditional and unconditional gets different results
- simpson's paradox and policy implication
- confounder
- relates xx to

2022/10/29

1500<->3000

- 1500 mins, one easy way to inteprete the formula
- LOTP
- what to condition on
- LOTP application 1700 mins, on Montyhall problem
- by symmetry
- asymmetry case
- simpler and extreme case
- simpson's paradox 2800 mins
- aggregate data together the outcome might flip
- next is the reason

2022/10/28

0000<->1500

- Monty hall problem, three door problem
- Monty always open a goat door
- lazy monty hall

### Lecture 7

2022/11/12

4500<->End

- event, the set that makes X(s)=1
- binomial distribution
- probability mass function
- X+Y ~ bin n+m,p

2022/11/11

3000<->4500

- no probability left for oscilation
- prob is 0 of gaming going on forever
- the definition of random variable
- vague
- 3808 mins, the difference between variables and R.V.
- R.V. is a function from sample space to R
- reconcile
- numerical summary
- 4322 mins, Defn Bernonlli
- P(X=1), X(s)=1
- Binomial n p

2022/11/09

1500<->3000

- 1500 mins difference equation
- discrete analog of differential equation
- be professional, and other's attack
- unfair solution will converge to fair solution when the game converges to fair

2022/11/08

0000<->1500

- p is P(A wins a certain round)
- condition on the first step
- a formula is written down


2022/03/29: ðŸ’« 2618/5145 , it has someting to do with Lecture 5, law of total probability <br>
2022/03/30: 2618 around, just to review basing on the law of total probility, see what is the new understanding <br>
2022/03/31: finished, excellent course, random variable, is a function which maps result happened in sample space S to X(s), then you got a distribution, the distribution indicates the variness/randomness of the variable, PMF is just like, P(X=3) if you through a coin, probability of number of heads equals to 3 <br>


2022/05/14:

0000<->3000 mins
0100 mins, statistics 110 5 word, conditioning the soul of statistics, r.v. and its distribution;
0913 mins, random walk, absorbing states, TBR eigen value and eiven vector;
1057 mins, recursive property;
1206 mins, condition on something, wish something;
1500 mins, difference equation;
1900 mins, solve differential equation, one method is to guess;
2621 mins, lowbetaw TBR, 0/0;

2022/05/19:
finished,
3000<->End
3306 mins, gambler's ruin, says probability of game going forever, because the result of P(A)+P(B)=1;
3400 mins, r.v.;
3900 mins, r.v. is a function, that map an abstract outcome to a real number;
4500 mins, X=1 is event, the event is {s:X(s)=1};
4754 mins, distribution is blue print of each probability that a r.v. will be a specific number;
### Lecture 8

2022/12/01

3530<->End

- write down the formula is not end of proof, you also need to check if it fits the sanity check
- if the sample size is big also if the number that choose is small, with replacement and without replacement concides to with replacement

2022/11/30

3000<->4500

- independent and the same probability of success
- a function from sample space to a number
- has k tagged elk
- if choose k from w, if k is bigger than w, then the C is 0
- sampling with replacement is binomial
- sampling without replacement is hypergeometric

2022/11/28

3000<->4500

- if it is independent, it is binomial, if it is not, it is not
- number of aces in the deck
- the elk problem
- 4350 mins, hypergeometric
- TBRT

2022/11/26

1500<->3000

- hybird variable
- sanity check
- binomial therom
- independent we know x without knowing anything about j
- 2850 mins, by independent
- 3000 mins vandermonde

2022/11/25

0000<->1500

- Bin(n,p)
- story
- X=X1+X2+...+Xn, Xj=1 or 0 depends on if the trial is success or failure
- independent, identical, distribution
- R.V. is a function and distribution, how the probability distributed
- x=7 is an event, X<=7 is an event
- cumulative distribution function
- discrete, something you can list

2022/03/31: 2111/5023 around 14 minutes CDF and PMF, both are a way of describing distribution, CDF P(X<=x), PMF P(X=aj) only applies for discrete problem <br>
2022/03/31: finished, around 2857 minutes by independence, knowing A gives no information about B, vandermonte sigma j=0 to k(m choose k-j times n choose k)=m plus n choose k, 10/100000 will make the difference between with replacement and without replacement sort of the same
### Lecture 9 <br>

2023/04/03

3500<->End

- hyper geometric is n choose k without replacement
- geometric is number of faiures before the first success
- binomial is n choose k with replacement, holding n fixed
- q to the fifth
- p times q to the kth is the formula of the PMF of geometric distribution
- story proof of expected value of a geometric distribution

2023/04/02

3000<->4500

- the single most useful thing in expectation
- even X Y dependent, linearity is still true
- this part is not about geometric itself, it is an application of linearity
- fundamental bridge
- OK the next part is geometric
- Geom P count number of failures before the first success

2022/12/16

XX<->End

- reframe and construct a formula from a known and existing formula
- X~(Geom(p)), E(X)
- iteration way to calculate Ex

2022/12/15

3000<->4500

- binomial formula, if you rephrase it it is (p+q)^n=1
- linearity
- even if X Y are dependent
- np by linearity, since X=X1+X2+..+Xn
- 3800 mins, by indicator, by linearity, by symmetry, by fundamental bridge
- geometric distribution
- Geom(p)
- number of failures before the first success
- geometric series gives the geometric probability name
- binomial therom gives the binomial distribution name

2022/12/14

1500<->3000

- average one number summary
- sum over finite list
- indicator R.V.
- E(X)=P(A)
- A occur
- the rest part sum to 1, binomial therom

2022/12/13

0000<->1500

- P(X<=x) as a function of real x, is CDF
- P(X=1) 2 3 4 is PMF, is the jump
- right continuous
- properties of CDF
- increasing, x tend to infinity
- joint CDF
- knowing of probability of one case, doesn't tell you the probability of another case, that is independent

2022/03/14: ðŸ’« finished, in order to understand so called taylor Expectation in link [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/03/31: finished, 2635 minutes Expectation and P has a bridge; 3248 minutes linearity, EX+Y=EX+EY no matter it is dependent or independent; bridge X={1 if A, 0 otherwise, this is indicator R.V. ; 4158 check PMF, geo distribution; 3827 by symatry and bridge

2022/05/24:

0000<->1500 stop at average and mean

0000 mins;

- CDF is a function of real x, not X
- x-> minus infinity, F(x)->0, x -> infinity, F(x)->1
- independence slogan is multiply
- joint probability
- independent of r.v.
- 

1500 mins;

2022/05/25:

1500<->4000

1500 mins

- 2 ways of calculting mean
- fundamental bridge
- unweighted = same weight, weighted = different weight
- E(X) = sigmax x P(X=x) sum over x with P(X=x)>0
- E(X) = 1P(X=1) + 0P(X=0)=P
- indicator r.v.
- k depends on k, n does not depend on k
- QSN why he can re-write the formula, change k=0 to k=1 and why the following equation like that
- because he take one P out

3000 mins

- linearity, true if X and Y are dependent
- bin = np, since X=X1+X2+...+Xn, Xi are ber
- hypergeometric, linearity + indicator + symmetric + fundamental bridge
- 5 card hand, X=#ace, E(X) is the question
- a dependent case of linearity

4500 mins

2022/05/26:

finished,
4000<->End

4000 mins

- geometric distribution is different with hyper geometric
- TBR hyper geometric, just like binomial but not replacement?
- # failures before the first success , each trial is a bern
- Geom(p)
- check if the PMF valid
- X ~ Geom(p), E(X)=q/p
- 

End mins

### Lecture 10 <br>

3000<->End

2024/07/03

- Putnam
- local maxima
- middle maxima, conner solution maxima
- not independent
- 3900 st Petersburg paradox
- gambling addict

2023/01/05

3440<->End

- intermediate point, end point
- infinity=E(2^X) not equal 2^EX=4
- EX=2???

2023/01/03

3000<->4500

- Putnam exam
- Random permutation, all the permutation are equally likely
- local maxima
- on average how many local maximum
- indicator R.V.
- 7 is bigger than 4 is not independent with 7 is bigger than 5
- St Peterburg paradox
- Y=2^X find E(Y)

2023/01/02

1500<->3000

- r.p negative binomial
- number of failure before the rth success
- indep bern trial
- Xj~Geom(p), Xj are independent
- X~FS(p)
- Y=X-1 (Y and X means number)
- Putnam

2023/01/01

0000<->1500

- 2 ways of calculate average, naive way, weighted way
- 0500 mins, wishful thinking
- add 2 function
- X(s), Y(s)
- undemocratic

2022/12/31

0000<->1500

- expectation doesn't exist
- TBRT
- X=0 X=1 X=2 X(s)P({s})
- negative binomial

2022/03/14: ðŸ’« 0610/5010 in order to understand so called taylor Expectation in link [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/03/31: 2230/5010, 1026 minutes, add 2 functions = compute 2 function and add the result; ends at negative nomial distribution <br>
2022/04/01: finished, round 29 minutes negative binomial distribution, first success distribution; 39 minutes, indication + linearity + symetry, and pubble world
### Lecture 11 <br>

2700<->End

2023/02/13

- how many rain drop hit this piece of paper in a minute
- small probability and big number of trials
- he said rain might not be exactly independent
- 2 rain might fall in one small cell
- 1000 factorial is hard for computer to manage
- 3 people birthday problem is difficult to handle in the old way
- 3900 understand the probability and expectation
- n choose 3 is big number number of trial is large, each trail is a small group of people, the indicator reflect the same birthday is unlikely
- not independent, 123 and 124
- the last discrete distribution

2500<->4000

2023/02/12

- see how the converge
- the definition of e^x
- show binomial converge to poisson
- even though n is 23, n choose 3 is large
- triplet
- in increasing order
- exact expectation

1000<->2500

2023/02/11

- discrete model most often used in practice
- large trial, small chance of success
- there are a lot of them
- pois, some cases there is upper bound
- #of Aj's occur is approx pois, lambda is sum of pj
- P(lambda), lambda is sum of pj
- limit kick in
- 2400 starting setup
- E(binomial) is np, set lambda =np, constant
- try to explore the connection between them

2023/02/09

1000<->2200

- independent, weakly dependent
- binomial np converge to pois
- small prob of success, large number of trial
- linearity doesn't care dependency
- need to check pois book

1500<->3000

2023/02/08

- pois paradiagm
- pois approximation
- weekly independence
- TBRT
- n choose k

0000<->1500

2023/02/07

- confuse with r.v. and its distribution
- word is not the thing, the map is not territory
- r.v. is a house, distribution is blueprint of the house
- valid
- #emails in an hour
- empirical, but this is an approximation
- #choclate chip in choclate cookie

2022/04/01: finished, around 21 minutes, by linearity, binomial converge to poisson, e^x = 1 + e/1 + e^2/2 + ... e^n/n! ; need to check calculus, rate of change, law of lopital <br>
2022/04/26: finished, 0500 mins, random variable - house, distribution - blue print;
0750 mins, poisson, P(X=k), k=0,1,2 lambda>0;
1300 mins, poisson like binomial, number of success;
2200 mins, poisson can have different Pj, events can be dependent;
2900 mins, e^x = (1+x/n)^n, compound annual ?interest?;
3700 mins, Iijk indicator R.V.

### Lecture 12 <br>

2023/02/27

-15mins<->End

- VAR X
- need PDF of Y
- traditional way is to find out distribution of gx first, then calculate the expectation
- by LOTUS, you can use the distribution of x
- strictly increasing makes inverse of it still hold inequality, and continuous

2023/02/26

- uniform distribution
- completely random, the probability for all the points are the same
- uniform probabity is propotional to length
- F(x) increases linearly
- Law of the unconscious statistician, LOTUS
- variance of unif(0,1)
- from uniform you can simulate any distribution no matter how complicated it is
- universality of uniform

2023/02/25:

1500<->3000

- FTC version 2
- foundamental therom of calculus
- F is assumed to be always differentiable
- one number of summary
- absolute value, V shape, not differentiable
- mile, square of mile
- EX is a constant
- Variance inequality
- uniform distribution

2023/02/24

0000<->1500

- PMF PDF
- probability per something, PDF probability density function
- defn, r.v X has PDF fx if P(a<=X<=b), integrate this PDF you get probability
- to be valid, fx>=0 integrate to be 1
- in a very small interval, the integral can be function times a constant
- continuous in this case means x can take continuous variable
- F is CDF, P is PDF PMF

2022/04/02: finished, around 1616 minutes FTC from calculus; 3803 minutes, take a function of R.V. is a R.V. ; law of the unconsicious stastician, LOTUS E(g(x))=accumulate from -infinite to +infinite g(x)fX(x)dx; uniform can be everything, just like a indicator I, 4907 minutes, P(F-1(u)<=x)=P(u<=F(x)) because CDF is continously increasing <br>
2022/04/27: finished, 0300 mins, fX(x) specific for PDF, P(X=x) is PMF, f(x) is not probability but it is PDF, intergral is probability;
1500 mins, FTC;
1839 mins, assume derivative exist, for CDF;
2039 mins, expectation is one number summary, variance is spread, absolute value is not differeantiable;
3216 mins, uniform probility propotion to length, completely random;
3924 mins, LOTUS first show;
4423 mins, unif(0,1) can generate all distribution;
4800 mins, proof of uniform is universal, condition of inverse, 1. strictly increase, 2. continuous, to prove this THM you need to know what is CDF, P(X<=x)=F(X)
### Lecture 13 <br>

2023/03/11

3600<->End

- infinite integral and finite integral
- odd function, by symmetry
- integrate by part, one piece easy to integrate, another piece easy to differentiate
- infinite integral and finite integral and integral by part
- var of normal distribution
- standard normal = 1-standard normal, by symmetry

1500<->4000

2023/03/10

- independence, joint PMFs, joint CDFs
- fully independence
- pair wise independence is not enough to claim independence
- give him credit
- adding a large number of r.v. the result is going to be in the same shape, bell shape curve
- dding a lot of iid looks normal
- c is whatever constant we need to make function to be one
- write the same thing twice
- understand how to rearrange the order of elements in a formula
- jacobian, read math review
- transform in more than one dimension, times it by jacobian

2023/03/09

0000<->1500

- start with a CDF, not to start with a random variable
- rewrite the formula in terms of u
- the value of inverse function and simulation
- linear is uniform, u square is not uniform

2023/03/08

0000<->1500

- garbage in garbage out in bayes rule
- any function has the property of the CDF then it is a CDF
- self referential
- TBRT
- take one example exponential distribution
- 1100 mins simulation example, and universality example
- solve the inverse equation in terms of another variable
- symmetry of uniform
- linear of uniform is uniform, non linear is not uniform

2022/04/02: finished, 0039 minutes court UK, can't use bayes to defends; 0701 take a function of R.V. is still R.V.; 1200 minutes, simulation; 1455 minutes, linear uniform -> uniform, non-linear uniform -> non-uniform; 1640 independent R.V. and independent event; 3508 double intergral; 3743 handout, jacobian, math about integration <br>
2022/05/02: finished, 0300 mins, universality of universe, CDF, right continus, <- = 0, -> = 1, strictly increase;
1-1/e^x, exponential distribution;
1339 mins, 1-unif ~ unif, symmetry of unnif, a+bu is unif on some interval;
1800 mins, definition of independent, TBR the first time independent is mentioned;
participating;
3500 mins, merge 2 intergral to a double intergral, because when you do it one by one, you will treat one as constant;
3700 mins, Jacobian, TBR, in math handout;
2100 mins, case of pairwise independent <> independent;
3100 mins, taylor series and e^x, antiderivative, porlar coordinate;
3900 mins, intergral e^-u du = 1;
4800 mins, integral by part
### Lecture 14 <br>

3400<->4000

2024/07/02

- independent var(x+y)=VAR(x)+var(Y)
- i.i.d identical independent distribution
- symmetry
- product of indicator variable is an indicator variable
- 3939 mins, second moment of binomial

3400<->End

2023/03/22

- if 2 variables are independent, var x+y is varx + y
- prove LOTUS for discrete sample space
- S:X(s)=x
- seems he didn't say why the probability of gx is the same as x

2023/03/21

3000<->4500

- derive variance of poisson
- get cross terms
- I1 times I2 is indicator of success on both trials
- second moment of binomial
- hyper geometric, geommetric
- prove LOTUS for discrete sample space

2023/03/20

1500<->3000

- the relationship between CDF P and phi
- understand what does capital phi mean
- even though you have negative number, LOTUS says the flavor still work
- replennish
- from expectation of poisson to variance of poisson

2023/03/19

0000<->1500

- EZ first moment, EZ^2 second moment
- EZ^3 thrid moment
- -Z is standard normal as well
- rescaling things
- variance is not in the linear world
- x is not iid with itself, x is strictly dependent with itself
- standarization

2022/04/02: finished, 131 minutes 1st moment, 2nd moment; ðŸŒŸ idea mind flow, key ord and their reason; 1030 minutes, var; 1856 minutes, sum of iid, normal X1-X2~(u1-u2, sigma1^2+sigma2^2); 4458 minutes, prove LOTUS

2022/05/09:
0000 mins,
Normal, E(Z)=0, VAR(Z)=E(Z^2)=1, E(Z^3)=0
0417 mins, -Z is a normal by symmetry;
0522 mins, mean location, SD scale;
0706 mins, VAR(miu + sigma z);
0922 mins, P(X=1)=1 VAR(X)=0;
1037 mins, VAR(X+Y)=VAR(X)+VAR(Y) if X and Y are indepenent, otherwise it doesn't hold;
1230 mins, if you add X+X, they are the same, it will magnify the variability;
1502 mins, derive PDF and CDF of a normal that is with offset location and magifiny of sigma
1859 mins, add 2 normal, the distribution is still a normal with miu1+miu2, sigma1^2 + sigma2^2
X1-X2 has exactly the same property;
Not only they have the expected miu and sigma, they are also normal;
68-95-99.7 rule;
2400 mins, another way of writing PMF;
USF, taylor series, euler formula, put it somewhere so taht you can read;
3138 mins, possion has mean lambda, and variance lambda;
geometric dist is an analogous of exponential dist;
3726 mins, symmetry, indicator r.v. , linearity;
3840 mins, product of indicator r.v. is an indicator r.v.
4015 mins, expect I1 and I2 happens, it is just p1*p2;
4109 mins, hyper geo metric, not independent;
4344 mins, proof of LOTUS TBRT;
4458 mins, r.v. is a function that map sample to x;


### Lecture 15

2023/04/06

2200<->End

- change the variable used in LOTUS, make the problem easier
- swapping success and failure
- number of emails getting in time t
- find PDF of T, time of first email
- 3700 mins derive a exponential distribution
- R.V. is a random house, distribution and CDF is the blue print

2023/04/05

1500<->3000

- 2000 mins, understand symmetry and linearity
- CDF take a derivative is fx, fx is PDF

2023/04/04

0000<->1500

- harmonic series
- TBRT why use T2-1 T3-1
- Fx can have domain on everywhere, Fx have a range of 0 1
- 1300 mins, a good practice in thinking universality

2023/04/01

0000<->1500

- coupon collector
- geometric
- linearity hold under both independent and dependent case
- TBR Geometric
- 1200 mis universality of the universe
- logistic distribution

### Lecture 16 <br>

0000<->End

2024/07/05

- exponential distribution
- lambda
- PDF, probability density function
- CDF culmulative distribution function
- integrate PDF get CDF
- 0 to x integration
- 1-e^(-lambdax)
- moment were briefly mentioned in here also
- waiting to get a call, memoriless property
-conditional expectation was briefly mentioned in the last two minutes 1600<->1800

2022/04/02: ðŸ’« finished, 1144 memoriless propoerty, exponential is the only memoriless distribution; 1704 mins E(X|x>a) = a+E(X-a|x>a) = a + 1/lambda

2022/05/08: 
0200 mins, Exponential distribution, TBR hyper geometric distribution; TBR MGF
0530 mins, Exp(1), Y=lambdaX;
0809 mins, intergration by part;
1132 mins, exponential distribution, memoriless property; binomial waiting in the discrete time, exponential waiting in the continuous time;
1446 mins, survival function, P(X>=s);
1640 mins, exponential prob is the only one memoriless in continuous , geometric is the only memoriless in discrete;

### Lecture 17 <br>
#### REX 1 2022/04/02
#### REX 2 2022/07/22

3000<->4000

2024/07/03

- constant with respect to z

1600<->3000

2024/07/02

- exponential is the only continuous memoriless
- MGF, another way to describe distribution
- function of random variable is a random variable
- moment of distribution
- taylor series
- all the moment sitting there in the taylor series
- MGF determines the distribution, same MGF same distribution
- same CDF
- aside from
- MGF of X+Y is E(et(X+Y)) if independent

0000<->1000

2024/07/02

- in continuous time
- in discrete time
- memoriless, you are good as new
- you can't make partial progress, you have gradual progress
- 1-CDF

2022/07/22:

End minus 15 min<->End

- update use bayes rule
- laplace rule of succession
- find posterior 
- p is r.v. in this case
- |p means treating p as constant
- distinguish P and f

2022/07/21:

3148<->4648

- TBRT
- by LOTUS, we get the MGF of normal distribution

2022/07/20:

1648<->3148

- 1730 mins moment generating function
- M(t)=E(etX)
- taylor series, take derivattive and set it as 0, cef of t^n/nfactorial
- SIGMAx^nt^n/nfactorial
- real analysis, and infinite sum
- MGF determines distribution
- independent, you can split the product
- bernp, MGF
- and thus binomial

2022/07/19:

0000<->1648

- geommetric and exponential,  both memoriless distribution in discrete world and continuous world
- aha moment is a memoriless case
- proof of exponential is the only memoriless in continuous case
- TBRT
- G(m/n t)
- G is continuous so you can swap and function G

2022/03/14: ðŸ’« MGF [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/04/02: 3720/5044, 1:00 mins, conditional probability; 910 mins, prove the uniqueness of exp memoryless property; 2238 finite sum is applicable for linearity, infinite sum need to take course real analysis; 2430 mins, interpretation of MGF; 2630 mins, MGF determines distribution; 3018 mins, MGF of X+Y, make X+Y to be easier to be detected; 3500 mins, normal MGF; M^(n)(0)=E(X^n) ; R.V. X has MGF M(t) = E(e^tx)

2022/05/08:
0000<->3000
0129 mins: conditional probability is probability, conditiaonal expectation is expectation;
0247 mins: bias answer;
0455 mins, memoriless property will say, average is 80, when you are 20, then your new E age will be 100
E(T|T>20)=20+E(T), otherwise E(T|T>20) > E(T)
0740 mins, cubic of exponential is a viable
0850 mins, memoriless property is a property of distribution not for a r.v.
0910 mins, if X is a continuous memoriless, then it is a X~Exp(lambda);
I can call myself as librian
1036 mins, memoriless property is G(s+t) = G(s)G(t);
1521 mins, continuous function can swap limit and function, after you take limit, you can make m/n from rational to real number
1800 mins, definition of MGF;
1820 mins, MGF is finite on some interval around 0 otherwise it is not useful, it must be exist to be useful;
2238 mins, if a series is finite, linearity work immediately;
2552 mins, M^n(0)=E(X^n);
2635 mins, MGF determines distribution;
2744 mins, MGF make sum of independent r.v. easy, TBR convolution, TBR C(9,10)=0;


### Lecture 18 <br>
2022/03/14: ðŸ’« MGF [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/04/03: finished, 138 mins moment of inertia; 826 mins benefit of using MGF; 1104 E(Z^n)=0 odd by symetry, normal distribution; 1350 mins geo series converges t<1, taylor series converges everywhere; 2129 mins convolution E(X+Y), take MGF of X * MGF of Y, the result is sum of pois is a pois if they are independent; 2907 mins joint distribution, condition for PMF joint distribution; 4230 mins simple extrem case, analysis method <br>
### Lecture 19 <br>
2022/04/04: finished, 
913 mins, conditional PDF;<br>
347 mins, E g(x,y) by LOTUS;<br>
4100 mins, checken egg problem;<br>
4442 application of law of total probablity;<br>
4600 mins, remove redundancy<br>
### Lecture 20 <br>
2022/04/05: finished,
0000 mins, Ex distance between 2 uniform;
0055 mins, Ex distance between 2 iid standard normal;
independent joint PDF of normal;
0333 mins, MGF applicatioin;
"Know more people", cyber way of interpretation, I got what they say, I store it, I have a map;
0730 mins, easy function;
1600 mins, multinomial;
2150 mins, lumping property;
2600 mins, conditional probability;
3330 mins, cauchy distribution;
3400 mins, symmetry;
4407 mins, u substitution;
4701 mins, LOTP;
4756 mins, independent integration CDF;
### Lecture 21 <br>
#### REX 2 2022/06/14
#### REX 1 2022/04/05
2022/04/05: finished,
2640 mins, dimensionless, unitless;
2959 mins, WLOG, without lose of generality; corr(x,y)=rou;
4200 mins, IA indicator R.V. of event A, IA^2=IA, IA^3=IA, IA*IB=I(A intersect B);
4400 mins, uncorrelated doesn't imply independent;
4800 mins, geometric distribution, use COV formula to prove VAR(X) for geometric distribution

2022/06/10:

0000<->1500

- study 2 RV, is COV
- x,y dependent pair, thus we define COV
- if X=Y then COV formula is variance
- if independent E(XY)=E(X)E(Y)
- use linearity you can rewrite covariance formula to another form
- COV of r.v. and c is 0
- COV(X,Y+Z) use formula and linearity
- bi linearity, treat one variable as constant, then it looks like a linearity for another variable
- it also looks like a distributive property
- play with COV(X+Y,Z+W)=COV(X,Z)+COV(X,W)+COV(Y,Z)+COV(Y,W)
- and a sigma form practice

2022/06/11

1500<->3000

- VAR(X1+X2)
- X1 X2 independent, COV is 0
- VAR(X1+X2+...+Xn), practice to write and arrange i and j and sigma
- X, Y indep, they are uncorrelated COV(X,Y)=0
- converse is false
- odd moment of standard normal with 0 expectation
- Y is a function of X, so Y is dependent of X, X also is a function of Y, at least Y partially determines X
- definition of correlation
- rewrite the function
- WLOG, without lose of generality

2022/06/12

finished,
3000<->End

-  VAR(X+Y) VAR(X-Y)
- proof of correlation is between -1 and 1
- COV i a multinomial, multi dimension of binomial
- competing game
- indicator r.v. to prove the var of binomial
- IAIB = ? intersection
- prove bernuli firstm ten prove binomial
- indicator r.v. practice
- hyper geometric proof

### Lecture 22 <br>

2022/04/06: finished, 
100 mins, hyper geom(w,b,n), withoug replacement binomial;
540 mins, finite population correction;
1101 mins, transformation;
1705 mins, log normal;
2355 mins, jacobian;
2600 mins, convolution - fancy name of sum;
4000 mins +, shenon information theory;<br>

2022/05/05: finished,
0038 mins, hyper geometric;
0220 mins, VAR and COV, expansion of VAR(SIGMA Xi);
0535 mins, finite population correction;
0736 mins, transformation, fY(y) = fX(x)dx/dy, y = g(x), x = g-1(y);
1648 mins, log Normal, don't seperate dx/dy unless you interprete it right;
2115 mins, random vector, n dimension transformation;
2345 mins, Jacobian, TBR, matrix of all possible partial derivative, reciprocal;
2746 mins, convolution, fancy word of sum of random variable;
3212 mins, you can swap derivative and intergral, there is a theory proves that;
3357 mins, probability can be used to prove existence of something that you can't exibht? TBRT (to be reviewed, this);
3916 mins, shennon theory, TBRT;
### Lecture 23 <br>

3400<->4900 End

2023/08/24

3000<->4500

2023/08/23

- weather derivative
- payoff is function of financial asset
- St
- g()
- E()
- choose RV correctly
- bivariate distribution
- start off
- apreciate A to B
- warrant
- right is not obligation, is a option

2023/08/22

0000<->1500

- start with beta, end in beta
- generalized laplace rule
- reminiscent
- billiards
- endowment
- miss out
- twelve thirteen

2023/08/21

0000<->1500

- generalized uniform distribution
- bounded by 0 and 1
- but not flat
- c is to make the fx to be 1 after taking integral
- asymtotic
- uniform prior connect with Laplace sun rising
- posterior reverse X|p to p|X
- LOTP

2023/08/20

0000<->1500

- beta is a family of distributions
- often used as prior for a parameter in (0,1)
- conjugate prior
- posterior
- integrate over on p, does not depend on p

2022/04/07: finished, 0830 mins conjugate prior;
1049 mins, bayesian statistics;
1620 mins, laplace therom;
2300 mins, doing calculus without calculus;
2602 mins; finance STAT123 course, the same as the teacher in MIT finance math course;
3320 mins, F(R.V.) is a R.V.;
4400 mins, TARP;
4200 mins, FX problem puzzle
2022/04/24: finished, 0225 mins, generalized uniform is beta, bounded by 0 and 1, not flat, beta(a,b), a>0,b>0;
0728 mins, conjugate prior to binomial;
1053 mins, X is observed data, X|P ~ Bin(n,p), P~B(a,b) - prior;
laplace?uniform?;
f=PDF;
1604 mins, interesting explaination of beta;
1741 mins, 1st moment beta, 2nd moment still beta;
nomalizing constant;
2023 mins, bayes billiards;
2415 mins, PDF of uniform is 1;
4420 mins, warrant = call option;
4725 mins, strike price;
4825 mins, LOTUS;

2022/06/01:

0000<->1628

0000 mins

- beta distribution
- integral get beta function
- conjugate prior to binomial
- prior, posterior
- TBR E calculation and COV calculation
- propotionality, why propotionality can work, OK, because constant is just to make integration of PDF to be 1

1500 mins

2022/06/02:

1500<->3000

1500 mins

- story proof

3000 mins

2022/06/03:

finished,
3000<->End

3000 mins

- g(ST), ST is a stock of a company, g is a derivative
- think probability and distribution, then you will think about how much you will pay in the end E(g(ST))
- binormial, bi-variate normal
- warrants = call option, is a derivative
- blackshoes formula

End mins

### Lecture 24 <br>
#### REX 3 2022/07/09
#### REX 2 2022/04/25
#### REX 1 2022/04/08
2022/04/08: finished, 0530 mins, sterling formula;
1133 mins, Gama function factorial formula;
1733 mins, normalizing constant of normal;
3600 mins, MGF proff gama distribution;
2150 mins, transformatijon Y=X/lambda;

2022/04/25: finished, 0600 mins, sterling formula;
0818 mins, gamma function is important;
1305 mins, intergral from 0 to infinity 1/e^x dx = 1;
1420 mins, intergration by parts;
2000 mins, Gamma(a,1), Gamma(a,lambda);
2130 mins, transformation;
2300 mins, Gamma related with many distribution;
2800 mins, memoriless property, poisson & exponential;
4256 mins, LOTUS

2022/07/06:

0000<->1500

- arithmatic sequence
- gamma 1/2 is sqrt(pi)
- normalizing normal, also has something to do with sqrt(pi)

2022/07/07:

0000<->1500

- understand the approximation and limitation
- gamma distribution came from game function
- more integration is needed
- the relation between gamma and integration
- 

2022/07/08:

1500<->3000

- normal formula, and the difference between the two
- how to turn a formula to PDF, normalize
- Gamma(a,lamda), Gamma(a,1)
- poisson processes
- disjoint, joint intervals
- 2800 mins, poisson and exponential
- interarrival times are iid expo(lambda)

2022/07/09:

3000<->End

- negative binomial & geometric
- convolution
- list all the distributions
- induction
- MGF
- to understand this part, MGF, convolution, negative binomial, geometric, posson and exponential
- TBRT
- 4700 mins, the property of gamma function
- Gamma(a,lambda), what does the lambda mean

### Lecture 25 <br>
2022/03/29: ðŸ’« 432/4814, suddenly want to back to basic stuffs <br>
2022/04/09: finished, 332 mins, Beta Gamma, need to review previous 2 videos; transformation function;
900 mins, jacobian, take determinant, take absolute value;
1320 mins, independent definition;
2252 mins, independent E(XY)=E(X)E(Y);
2900 mins, order statistics dependent; Fx CDF fx PDF;
4230 mins, relation of order statistics and beta;
4523 mins, E(X) = E(X|A)P(A) + E(E|Ac)P(Ac) and its proof, using LOTP;
4642 mins, envolop paradox, the same as the movie 21 points said;
### Lecture 26 <br>

0000<->0500

2024/07/07

- law of total probability
- LOTP, condition things

2022/04/11: finished, 0300 mins LOTP;
2100 mins, partial progress;
2320 mins, iteration of Ew HH;
2700 mins, ted peter donnelly;
3400 mins, g(x)=E(Y|X=x), E(Y|X)=g(X);
3600 mins, eg E(Y|X)is a r.v.
### Lecture 27 <br>

0000<->0800

2024/07/07

- condition on event, condition r.v.
- what would happen if xx

2022/04/13: finished,0120 mins, best minimize mean square error is the purpose of E(X|Y)
0600 mins, E(Y|X=x) is function of x;
0900 mins, E(h(x)Y|X)=h(x)E(Y|X) taking out what's known;
E(Y|X)=E(Y) if X Y are independent
E(E(Y|X)) = E(Y) adam's law;
E((Y-E(Y|X))hx)=0, residual, uncorrelated;
1900 mins, using plain to understand E(Y|X)
2700 mins, re-arrange term and summation;
3300 mins, VAR(X|Y), EVE's Law;
3700 mins, add variance, just like Chi square
### Lecture 28 <br>

2000<->3000

2024/07/01

- 2400 Jensen inequality
- convex, second derivative
- derivative doesn't exist at the corner

2022/03/14: ðŸ’« Che inequality [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/04/11:  0000<->0830, 0500 mins, category error;
0727 mins, LOTP;
0830 mins, Adam's law; <br>
2022/04/13: finished, 1700 mins, how to argue in a court;
1900 mins, cauchy-schwarz E(XY) analogy to dot product;
2100 mins, 2D LOTUS; Jension inequality
2816 mins, E(g(X))>=g(E(X)) <- EX^2 >= (EX)^2, because VAR can't be negative;
3738 mins, fundamental bridge;
4345 mins, chebyshev; <br>
2022/05/04: finished, 700 mins, EX=sigma E(X|N)P(N);
0830 mins, adam's law E(X)=E(E(X|N)) E(X|N) means treat N as known;
1034 mins, Var(X) = E(VAR(X|N)) + VAR(E(X|N)) Eve's law;
1300 mins, MGF, TBR MGF,  sigma X = PI MGF of each X;
1900 mins, cauchy schwarz inequanlity, intuitively means corr<=1, it shows correlation how it looks like when miu = 0;
when X and Y uncorrelated, E(XY) = E(X)E(Y);
2412 mins, Jension inequality, g is convex E(g(x)) >= g(E(X)), EX^2 >= E(X)^2 intuitively understanding;
3446 mins, Markov inequality, use bridge indicator;
4100 mins, intuition of Markov;
4200 mins, chebyshev
### Lecture 29 <br>
2022/03/14: ðŸ’« Che inequality [Financial math expectation problems](https://github.com/MediciHouse07/Learning_Records/blob/main/finance_math.md#lecture-3-) <br>
2022/04/13: finished, 0312 mins, LOLN;
1800 mins, degenerate distribution;
3300 mins, by definition;
3900 mins, factorial grows too fast;
4100 mins, appromximation;
4330 mins, fundamental theory CDF - CDF = PDF;
4600 mins, n large & p, pois converge to normal

### Lecture 30 <br>
2022/04/14: finished, 0141 mins, chi square n, chisquare 1 -> take 1 N(0,1) is Gamma(1/2,1/2), chi square n is Gamma (n/2,1/2),
0816 mins, Gosset 1908 student-t;
1337 mins, Cauchy and student t;
2500 mins, LOLN;
2905 mins, MVN;
3000 mins, Random vector;
ind->uncorrelated, uncorrelated!=>ind for univariate, while it seems work for multi-variate
COV(X+Y,X-Y)

### Lecture 31 <br>

#### REX 3 2022/06/25
#### REX 2 2022/05/03
#### REX 1 2022/04/15

2022/04/14: 0<->1928, 0430 mins, stochastics process;
0730 mins, 171 class stochastic process;
1928 mins, lost interest for today <br>
2022/04/15: finished , 1920<->End
2230 mins, Markov monte carlo;
2600 mins, Markov story;
4000 mins, stationary;<br>
2022/05/03: finished, 0346 mins, TBR ineuality;
0519 mins, stochastic processes, X0 X1 X2 with some dependence, one step beyond iid;
0732 mins, cont/discrete time, cont/discrete space
1049 mins, Markov property;
1159 mins, past future, conditionally independent, given the present;
1358 mins, homogeneous, qij independent of t;
2333 mins, Markov chain, converge to a distribution you are interested in, this is MCMC Markov chain monte carlo, build your own MC, TBR fourier;
2641 mins, LOLN hold on iid, free will, LOLN hold in Markov;
3300 mins, LOTP;
4000 mins, stationary, steady state, converge, $\vec{s}$$Q$ = $\vec{s}$, also it is eigen value and eigen vector

2022/06/23

0000<->1500

- chronological
- markov chain, example of stochastic processes
- discrete r.v. and discrete space
- think about continuous r.v. and continuous space
- P(xn+1=j|xn=i,xn-1=xi-1...)
- past and future are conditionally independent given the present
- homogeneous, qij this doesn't depend on time, that means there are some qij depend on time

2022/06/24:

1500<->3000

- transition matrix, stationary property
- markov chain to simlulate something
- LOLN holds in Markov chain case as well
- 1 by M matrix is a vector
- the reason that he uses vector times Q is because of the way he define Q, his Q is on row wise not column wise

2022/06/19:

3000<->End

- he also use row vector, 1 by M vector
- Xn and,  s vector PMF at time n
- s is 1 by M matrix, Q is M by M matrix
-  does it exist, is it unique, stationary dist is referring s vector


### Lecture 32 <br>
#### REX 1 2022/04/16 
2022/04/16: finished, 0640 mins, irr irreducible, you can go anywhere from anywhere;
0812 mins, recurrent, start at a state return to a state; otherwise, transient;
1330 mins, absorbing state;
2230 mins, Markov chain, si=1/ri, ri start at i;
2700 mins, prob vector;
2930 mins, reversible markov chain;
4500 mins, proof of chain, qij=1/di

2022/06/21

0000<->1540

- irreducible chain means you can go anywhere from anywhere
- the opposite is reducible
- reducible can be split to irreducible
- state is recurrent, P =1 of returning to that state
- the opposite is transient
- 1300 mins a case of turning a recurrent structure to transient
- 1400 mins a case of recurrent and transient mix, also a visualization of gambler's ruin
- periodic chain
- 1540 mins summary

2022/06/22

1500<->3000

- s vector is stationary with trans matrix Q
- OK, TBR lecture 31
- TBRT why it is unique
- still TBR markov chain
- reversible MC TBRT

### Lecture 33 <br>
2022/04/16: finished, 1700 mins, Markov chain - google;
2000 mins, google story;
3600 mins, teleportation = fancy word of not follow the hyperlink's instruction, google set the threshold as 0.85
### Lecture 34 <br>
2022/04/15: finished, 0730 mins, probability model->data, inference data->parameter;
1940 mins, mostly harmless econometric book

